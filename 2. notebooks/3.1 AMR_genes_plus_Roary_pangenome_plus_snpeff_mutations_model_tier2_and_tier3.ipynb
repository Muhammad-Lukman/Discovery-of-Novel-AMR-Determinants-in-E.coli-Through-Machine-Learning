{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mk8uEpK5m2qy"
   },
   "source": [
    "# **Training Tier 2 XGBoost Models**\n",
    "\n",
    "**`Hypothesis:`** \"*Can addition of mutation have any impact on model performance?*\"\n",
    "In short\n",
    "\n",
    "*\"Tests if mutations ADD signal beyond genes.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edpEfT5rm7gy"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, classification_report, average_precision_score, precision_score, recall_score, f1_score\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wn7cWJgGm-Ji"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "tier2_df = pd.read_csv('/content/drive/MyDrive/amr_features/tier2_amr_genes_plus_mutations.csv', index_col=0)\n",
    "phenotypes = pd.read_csv('/content/drive/MyDrive/data/E.coli/phenotypic.csv', index_col=0)\n",
    "\n",
    "#align samples\n",
    "phenotypes.set_index('Isolate', inplace=True)\n",
    "common_samples = tier2_df.index.intersection(phenotypes.index)\n",
    "X = tier2_df.loc[common_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12245,
     "status": "ok",
     "timestamp": 1765226007390,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "yL5BiZ8Mm37p",
    "outputId": "e04421dd-5042-4b75-d2f1-f1ae6e11b2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TIER 2 MODEL: AMX\n",
      "================================================================================\n",
      "Data prepared for AMX. Total samples: 1089\n",
      "Resistance counts (R=1, S/I=0): AMX\n",
      "1    659\n",
      "0    430\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AMX: Training XGBoost model...\n",
      " - Train Samples: 871 (R=527, S=344)\n",
      " - Test Samples: 218\n",
      " - scale_pos_weight: 0.65\n",
      "\n",
      "Performance:\n",
      " Model trained. Test AUROC: 0.9355\n",
      "ROC-AUC: 0.936\n",
      "AUPRC: 0.9682\n",
      "Precision: 0.9826\n",
      "Recall: 0.8561\n",
      "F1 Score: 0.9150\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.82      0.98      0.89        86\n",
      "           R       0.98      0.86      0.91       132\n",
      "\n",
      "    accuracy                           0.90       218\n",
      "   macro avg       0.90      0.92      0.90       218\n",
      "weighted avg       0.92      0.90      0.90       218\n",
      "\n",
      "\n",
      "Computing SHAP values...\n",
      "\n",
      "Top 20 Features:\n",
      "    feature  shap_importance\n",
      "      TEM-4         2.069278\n",
      "   blaTEM-1         0.654300\n",
      "      OXA-1         0.329998\n",
      " ftsI_L192F         0.245078\n",
      "       sul1         0.227007\n",
      "  gyrA_V85F         0.199541\n",
      " ompC_T155P         0.194531\n",
      " ompC_Q196E         0.150207\n",
      " ampC_D367A         0.142412\n",
      "     sul2.1         0.135968\n",
      "  parC_E84V         0.134722\n",
      "blaTEM-1B_1         0.113770\n",
      "aph(3'')-Ib         0.112412\n",
      "       PmrE         0.109013\n",
      " phoQ_A482T         0.091048\n",
      "       aadA         0.090604\n",
      " gyrA_P215T         0.085260\n",
      "    SHV-102         0.082468\n",
      " gyrB_G684R         0.069568\n",
      "  parC_S80C         0.059863\n",
      "\n",
      "================================================================================\n",
      "TIER 2 MODEL: AMC\n",
      "================================================================================\n",
      "Data prepared for AMC. Total samples: 1089\n",
      "Resistance counts (R=1, S/I=0): AMC\n",
      "0    764\n",
      "1    325\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AMC: Training XGBoost model...\n",
      " - Train Samples: 871 (R=260, S=611)\n",
      " - Test Samples: 218\n",
      " - scale_pos_weight: 2.35\n",
      "\n",
      "Performance:\n",
      " Model trained. Test AUROC: 0.8829\n",
      "ROC-AUC: 0.883\n",
      "AUPRC: 0.7749\n",
      "Precision: 0.6316\n",
      "Recall: 0.7385\n",
      "F1 Score: 0.6809\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.88      0.82      0.85       153\n",
      "           R       0.63      0.74      0.68        65\n",
      "\n",
      "    accuracy                           0.79       218\n",
      "   macro avg       0.76      0.78      0.76       218\n",
      "weighted avg       0.81      0.79      0.80       218\n",
      "\n",
      "\n",
      "Computing SHAP values...\n",
      "\n",
      "Top 20 Features:\n",
      "   feature  shap_importance\n",
      "     TEM-4         1.405236\n",
      "  blaOXA-1         0.566872\n",
      "gyrA_T654S         0.209614\n",
      "ompC_G362R         0.201780\n",
      "  blaTEM-1         0.190400\n",
      "parC_V244L         0.136427\n",
      " parC_S80I         0.101112\n",
      "      sul1         0.100927\n",
      "    strA_4         0.090305\n",
      "gyrB_E680K         0.077884\n",
      "  tet(A)_4         0.077656\n",
      "  CTX-M-15         0.073000\n",
      "parC_S658R         0.067200\n",
      "  tet(B)_4         0.066805\n",
      "     dfrA7         0.063848\n",
      "parC_G107C         0.058050\n",
      " APH(6)-Id         0.054816\n",
      "gyrA_L492V         0.054788\n",
      "robA_T213P         0.052489\n",
      "parE_V450F         0.052075\n",
      "\n",
      "================================================================================\n",
      "TIER 2 MODEL: CIP\n",
      "================================================================================\n",
      "Data prepared for CIP. Total samples: 1089\n",
      "Resistance counts (R=1, S/I=0): CIP\n",
      "0    908\n",
      "1    181\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CIP: Training XGBoost model...\n",
      " - Train Samples: 871 (R=145, S=726)\n",
      " - Test Samples: 218\n",
      " - scale_pos_weight: 5.01\n",
      "\n",
      "Performance:\n",
      " Model trained. Test AUROC: 0.9812\n",
      "ROC-AUC: 0.981\n",
      "AUPRC: 0.9623\n",
      "Precision: 1.0000\n",
      "Recall: 0.9167\n",
      "F1 Score: 0.9565\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.98      1.00      0.99       182\n",
      "           R       1.00      0.92      0.96        36\n",
      "\n",
      "    accuracy                           0.99       218\n",
      "   macro avg       0.99      0.96      0.97       218\n",
      "weighted avg       0.99      0.99      0.99       218\n",
      "\n",
      "\n",
      "Computing SHAP values...\n",
      "\n",
      "Top 20 Features:\n",
      "                                 feature  shap_importance\n",
      "                               gyrA_S83L         2.566045\n",
      "                               gyrA_V85F         2.522013\n",
      "                               folP_E73A         0.428618\n",
      "                               phoP_G53*         0.274854\n",
      "                              ompC_G133R         0.197466\n",
      "                              phoQ_Q479K         0.187509\n",
      "phoP_frameshift_insertion_1bp_pos1189670         0.178857\n",
      "                              gyrA_T658P         0.177675\n",
      "                              parE_Q341E         0.152176\n",
      "                              phoQ_E473K         0.150829\n",
      "                                    sul2         0.137534\n",
      "                               parC_S80I         0.127622\n",
      "                              folP_R235C         0.100041\n",
      "                                   TEM-4         0.091255\n",
      "                              parE_L397F         0.083214\n",
      "                              gyrA_I198L         0.082870\n",
      "                                  sul2.1         0.082242\n",
      "                              gyrA_G613C         0.069531\n",
      "                              phoQ_K172E         0.068085\n",
      "                              gyrA_P636A         0.060299\n",
      "  drug   tier     auroc     auprc  precision    recall        f1 model_type  \\\n",
      "0  AMX  Tier2  0.935518  0.968152   0.982609  0.856061  0.914980    XGBoost   \n",
      "1  AMC  Tier2  0.882856  0.774933   0.631579  0.738462  0.680851    XGBoost   \n",
      "2  CIP  Tier2  0.981227  0.962259   1.000000  0.916667  0.956522    XGBoost   \n",
      "\n",
      "                                        model_params  n_features  n_samples  \n",
      "0  {'objective': 'binary:logistic', 'base_score':...        1236       1089  \n",
      "1  {'objective': 'binary:logistic', 'base_score':...        1236       1089  \n",
      "2  {'objective': 'binary:logistic', 'base_score':...        1236       1089  \n"
     ]
    }
   ],
   "source": [
    "#train for each drug\n",
    "results = []\n",
    "\n",
    "for drug in ['AMX', 'AMC', 'CIP']:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TIER 2 MODEL: {drug}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    #prepare labels\n",
    "    y = phenotypes.loc[common_samples, drug].map({'R': 1, 'S': 0, 'I': 0})\n",
    "    y = y.dropna()\n",
    "    X_drug = X.loc[y.index]\n",
    "\n",
    "    print(f\"Data prepared for {drug}. Total samples: {len(X_drug)}\")\n",
    "    print(f\"Resistance counts (R=1, S/I=0): {y.value_counts()}\")\n",
    "\n",
    "    #train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_drug, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    #calculate Class Weights for Imbalance, Resistance (1) is the positive class.\n",
    "    n_resistant = np.sum(y_train == 1)\n",
    "    n_susceptible = np.sum(y_train == 0)\n",
    "\n",
    "    if n_resistant > 0:\n",
    "        scale_pos_weight = n_susceptible / n_resistant\n",
    "    else:\n",
    "        #fallback if no resistant samples are in the training set (rare but safe)\n",
    "        scale_pos_weight = 1.0\n",
    "\n",
    "    #train XGBoost Model\n",
    "    print(f\"\\n{drug}: Training XGBoost model...\")\n",
    "    print(f\" - Train Samples: {len(X_train)} (R={n_resistant}, S={n_susceptible})\")\n",
    "    print(f\" - Test Samples: {len(X_test)}\")\n",
    "    print(f\" - scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "    #train model\n",
    "    model = XGBClassifier(\n",
    "        max_depth=6,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=scale_pos_weight,   #len(y[y==0])/len(y[y==1]),\n",
    "        random_state=42,\n",
    "        eval_metric='auc'\n",
    "\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #evaluate\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "    auprc = average_precision_score(y_test, y_pred_proba)\n",
    "    precision = precision_score(y_test, y_pred_proba.round())\n",
    "    recall = recall_score(y_test, y_pred_proba.round())\n",
    "    f1 = f1_score(y_test, y_pred_proba.round())\n",
    "\n",
    "    print(f\"\\nPerformance:\")\n",
    "    print(f\" Model trained. Test AUROC: {auroc:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
    "    print(f\"AUPRC: {auprc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['S', 'R']))\n",
    "\n",
    "    #SHAP analysis\n",
    "    print(\"\\nComputing SHAP values...\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    #get top 20 features\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_drug.columns,\n",
    "        'shap_importance': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values('shap_importance', ascending=False)\n",
    "\n",
    "    print(f\"\\nTop 20 Features:\")\n",
    "    print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "    #save results\n",
    "    results.append({\n",
    "        'drug': drug,\n",
    "        'tier': 'Tier2',\n",
    "        'auroc': auroc,\n",
    "        'auprc': auprc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'model_type': 'XGBoost',\n",
    "        'model_params': model.get_params(),\n",
    "        'n_features': len(X_drug.columns),\n",
    "        'n_samples': len(X_drug)\n",
    "    })\n",
    "\n",
    "    #save model and SHAP\n",
    "    model.save_model(f'/content/drive/MyDrive/models/tier2_mutations_genes_model_{drug}.json')\n",
    "    feature_importance.to_csv(f'/content/drive/MyDrive/amr_features/tier2_mutations_genes_feature_importance_{drug}.csv', index=False)\n",
    "\n",
    "    # Save SHAP plot\n",
    "    shap.summary_plot(shap_values, X_test, show=False)\n",
    "    plt.savefig(f'/content/drive/MyDrive/amr_features/tier2_mutations_genes_shap_summary_{drug}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "#save all results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('/content/drive/MyDrive/amr_features/tier2_mutations_genes_results_summary.csv', index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlAECuneqMd8"
   },
   "source": [
    "# **Train Tier 3 Models**\n",
    "- AMR genes\n",
    "- snp mutations\n",
    "- roary pangenome\n",
    "- phenotypic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPaQoXvdq4Va"
   },
   "outputs": [],
   "source": [
    "tier2 = pd.read_csv('/content/drive/MyDrive/amr_features/tier2_amr_genes_plus_mutations.csv', index_col=0)\n",
    "phenotypes = pd.read_csv('/content/drive/MyDrive/data/E.coli/phenotypic.csv', index_col=0)\n",
    "\n",
    "#align samples\n",
    "phenotypes.set_index('Isolate', inplace=True)\n",
    "common_samples = tier2_df.index.intersection(phenotypes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16475,
     "status": "ok",
     "timestamp": 1765226399304,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "WWb3fOCjqkMz",
    "outputId": "c03c1b88-5372-4e33-fae6-80a7dc4f9b48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TIER 2 MODEL: AMX\n",
      "================================================================================\n",
      "\n",
      "Tier 3 for AMX: (1089, 1736)\n",
      "Data prepared for AMX. Total samples: 1089\n",
      "Resistance counts (R=1, S/I=0): AMX\n",
      "1    659\n",
      "0    430\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AMX: Training XGBoost model...\n",
      " - Train Samples: 871 (R=527, S=344)\n",
      " - Test Samples: 218\n",
      " - scale_pos_weight: 0.65\n",
      "\n",
      "Performance:\n",
      " Model trained. Test AUROC: 0.9345\n",
      "ROC-AUC: 0.935\n",
      "AUPRC: 0.9670\n",
      "Precision: 0.9741\n",
      "Recall: 0.8561\n",
      "F1 Score: 0.9113\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.81      0.97      0.88        86\n",
      "           R       0.97      0.86      0.91       132\n",
      "\n",
      "    accuracy                           0.90       218\n",
      "   macro avg       0.89      0.91      0.90       218\n",
      "weighted avg       0.91      0.90      0.90       218\n",
      "\n",
      "\n",
      "Computing SHAP values...\n",
      "\n",
      "Top 20 Features:\n",
      "    feature  shap_importance\n",
      "      TEM-4         2.019426\n",
      "   blaTEM-1         0.445004\n",
      "      OXA-1         0.304583\n",
      "       tnpR         0.291128\n",
      "       ybeT         0.207582\n",
      "blaTEM-1B_1         0.191167\n",
      " group_3820         0.172340\n",
      "group_26397         0.135704\n",
      "     sul2.1         0.128192\n",
      "group_11074         0.125959\n",
      "     yhjK_2         0.124787\n",
      "group_14256         0.123120\n",
      " ftsI_L192F         0.107626\n",
      "       sul1         0.107268\n",
      " gyrA_P215T         0.094895\n",
      "group_10824         0.094750\n",
      "group_16945         0.090864\n",
      "  gyrA_V85F         0.085268\n",
      "       sopB         0.085136\n",
      "    SHV-102         0.083785\n",
      "\n",
      "================================================================================\n",
      "TIER 2 MODEL: AMC\n",
      "================================================================================\n",
      "\n",
      "Tier 3 for AMC: (1089, 1736)\n",
      "Data prepared for AMC. Total samples: 1089\n",
      "Resistance counts (R=1, S/I=0): AMC\n",
      "0    764\n",
      "1    325\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AMC: Training XGBoost model...\n",
      " - Train Samples: 871 (R=260, S=611)\n",
      " - Test Samples: 218\n",
      " - scale_pos_weight: 2.35\n",
      "\n",
      "Performance:\n",
      " Model trained. Test AUROC: 0.8928\n",
      "ROC-AUC: 0.893\n",
      "AUPRC: 0.7741\n",
      "Precision: 0.6420\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.7123\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.91      0.81      0.86       153\n",
      "           R       0.64      0.80      0.71        65\n",
      "\n",
      "    accuracy                           0.81       218\n",
      "   macro avg       0.77      0.81      0.78       218\n",
      "weighted avg       0.83      0.81      0.81       218\n",
      "\n",
      "\n",
      "Computing SHAP values...\n",
      "\n",
      "Top 20 Features:\n",
      "    feature  shap_importance\n",
      "      TEM-4         1.364596\n",
      "   blaOXA-1         0.655933\n",
      "   blaTEM-1         0.183520\n",
      " gyrA_T654S         0.164245\n",
      " ompC_G362R         0.145771\n",
      " parC_V244L         0.122127\n",
      "       tnpR         0.109442\n",
      "       yfeA         0.108424\n",
      " group_5884         0.107163\n",
      " group_3326         0.093166\n",
      "       wcaM         0.090660\n",
      " group_7896         0.082464\n",
      "group_16990         0.081746\n",
      "  parC_S80I         0.079954\n",
      "group_16885         0.079249\n",
      " robA_T213P         0.078363\n",
      "  group_312         0.075607\n",
      "group_17656         0.066960\n",
      "     insA_1         0.065795\n",
      "group_11770         0.063742\n",
      "\n",
      "================================================================================\n",
      "TIER 2 MODEL: CIP\n",
      "================================================================================\n",
      "\n",
      "Tier 3 for CIP: (1089, 1736)\n",
      "Data prepared for CIP. Total samples: 1089\n",
      "Resistance counts (R=1, S/I=0): CIP\n",
      "0    908\n",
      "1    181\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CIP: Training XGBoost model...\n",
      " - Train Samples: 871 (R=145, S=726)\n",
      " - Test Samples: 218\n",
      " - scale_pos_weight: 5.01\n",
      "\n",
      "Performance:\n",
      " Model trained. Test AUROC: 0.9655\n",
      "ROC-AUC: 0.966\n",
      "AUPRC: 0.9563\n",
      "Precision: 1.0000\n",
      "Recall: 0.9167\n",
      "F1 Score: 0.9565\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.98      1.00      0.99       182\n",
      "           R       1.00      0.92      0.96        36\n",
      "\n",
      "    accuracy                           0.99       218\n",
      "   macro avg       0.99      0.96      0.97       218\n",
      "weighted avg       0.99      0.99      0.99       218\n",
      "\n",
      "\n",
      "Computing SHAP values...\n",
      "\n",
      "Top 20 Features:\n",
      "                                 feature  shap_importance\n",
      "                               gyrA_S83L         2.518632\n",
      "                               gyrA_V85F         2.277664\n",
      "                              ompC_G133R         0.337972\n",
      "                                      rz         0.311536\n",
      "                               folP_E73A         0.296493\n",
      "                                    nmpC         0.285022\n",
      "                                    yedI         0.215266\n",
      "                               phoP_G53*         0.193534\n",
      "                             group_12513         0.188766\n",
      "phoP_frameshift_insertion_1bp_pos1189670         0.155285\n",
      "                              group_8907         0.144967\n",
      "                                    gatD         0.101428\n",
      "                                folP_F4Y         0.100439\n",
      "                              folP_R235C         0.094998\n",
      "                                   TEM-4         0.079708\n",
      "                                  yaiO_1         0.077930\n",
      "                              phoQ_Q479K         0.073657\n",
      "                              group_9126         0.070705\n",
      "                              phoQ_E473K         0.061476\n",
      "                                    ybcQ         0.057742\n",
      "  drug   tier     auroc     auprc  precision    recall        f1 model_type  \\\n",
      "0  AMX  Tier2  0.934549  0.967045   0.974138  0.856061  0.911290    XGBoost   \n",
      "1  AMC  Tier2  0.892810  0.774071   0.641975  0.800000  0.712329    XGBoost   \n",
      "2  CIP  Tier2  0.965507  0.956288   1.000000  0.916667  0.956522    XGBoost   \n",
      "\n",
      "                                        model_params  n_features  n_samples  \n",
      "0  {'objective': 'binary:logistic', 'base_score':...        1736       1089  \n",
      "1  {'objective': 'binary:logistic', 'base_score':...        1736       1089  \n",
      "2  {'objective': 'binary:logistic', 'base_score':...        1736       1089  \n"
     ]
    }
   ],
   "source": [
    "#train for each drug\n",
    "results = []\n",
    "\n",
    "for drug in ['AMX', 'AMC', 'CIP']:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TIER 2 MODEL: {drug}\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    roary_tier3 = pd.read_csv(f'/content/drive/MyDrive/pangenome_features/roary_filtered_{drug}_top500.csv', index_col=0)\n",
    "    tier3_combined = pd.concat([tier2, roary_tier3], axis=1, join='inner')\n",
    "    print(f\"\\nTier 3 for {drug}: {tier3_combined.shape}\")\n",
    "\n",
    "    X = tier3_combined.loc[common_samples]\n",
    "    #prepare labels\n",
    "    y = phenotypes.loc[common_samples, drug].map({'R': 1, 'S': 0, 'I': 0})\n",
    "    y = y.dropna()\n",
    "    X_drug = X.loc[y.index]\n",
    "\n",
    "    print(f\"Data prepared for {drug}. Total samples: {len(X_drug)}\")\n",
    "    print(f\"Resistance counts (R=1, S/I=0): {y.value_counts()}\")\n",
    "\n",
    "    #train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_drug, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    #calculate Class Weights for Imbalance, Resistance (1) is the positive class.\n",
    "    n_resistant = np.sum(y_train == 1)\n",
    "    n_susceptible = np.sum(y_train == 0)\n",
    "\n",
    "    if n_resistant > 0:\n",
    "        scale_pos_weight = n_susceptible / n_resistant\n",
    "    else:\n",
    "        #fallback if no resistant samples are in the training set (rare but safe)\n",
    "        scale_pos_weight = 1.0\n",
    "\n",
    "    #train XGBoost Model\n",
    "    print(f\"\\n{drug}: Training XGBoost model...\")\n",
    "    print(f\" - Train Samples: {len(X_train)} (R={n_resistant}, S={n_susceptible})\")\n",
    "    print(f\" - Test Samples: {len(X_test)}\")\n",
    "    print(f\" - scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "    #train model\n",
    "    model = XGBClassifier(\n",
    "        max_depth=6,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=scale_pos_weight,   #len(y[y==0])/len(y[y==1]),\n",
    "        random_state=42,\n",
    "        eval_metric='auc'\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #evaluate\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "    auprc = average_precision_score(y_test, y_pred_proba)\n",
    "    precision = precision_score(y_test, y_pred_proba.round())\n",
    "    recall = recall_score(y_test, y_pred_proba.round())\n",
    "    f1 = f1_score(y_test, y_pred_proba.round())\n",
    "\n",
    "    print(f\"\\nPerformance:\")\n",
    "    print(f\" Model trained. Test AUROC: {auroc:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
    "    print(f\"AUPRC: {auprc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['S', 'R']))\n",
    "\n",
    "    #SHAP analysis\n",
    "    print(\"\\nComputing SHAP values...\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    #get top 20 features\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_drug.columns,\n",
    "        'shap_importance': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values('shap_importance', ascending=False)\n",
    "\n",
    "    print(f\"\\nTop 20 Features:\")\n",
    "    print(feature_importance.head(20).to_string(index=False))\n",
    "\n",
    "    #save results\n",
    "    results.append({\n",
    "        'drug': drug,\n",
    "        'tier': 'Tier2',\n",
    "        'auroc': auroc,\n",
    "        'auprc': auprc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'model_type': 'XGBoost',\n",
    "        'model_params': model.get_params(),\n",
    "\n",
    "        'n_features': len(X_drug.columns),\n",
    "        'n_samples': len(X_drug)\n",
    "    })\n",
    "\n",
    "    #save model and SHAP\n",
    "    model.save_model(f'/content/drive/MyDrive/models/tier3_mutations_roary_genes_roary_model_{drug}.json')\n",
    "    feature_importance.to_csv(f'/content/drive/MyDrive/amr_features/tier3_mutations_roary_genes_feature_importance_{drug}.csv', index=False)\n",
    "\n",
    "    # Save SHAP plot\n",
    "    shap.summary_plot(shap_values, X_test, show=False)\n",
    "    plt.savefig(f'/content/drive/MyDrive/amr_features/tier3_mutations_roary_genes_shap_summary_{drug}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "#save all results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('/content/drive/MyDrive/amr_features/tier2_mutations_roary_genes_results_summary.csv', index=False)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QjUPm6GUBXb"
   },
   "source": [
    "### **Results:**\n",
    "Antimicrobial resistance mechanisms are antibiotic-specific: genes dominate `Î²-lactam` resistance, while `chromosomal mutations dominate fluoroquinolone resistance` for CIP."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPS8RZ1wWWTNtQKDdjzFiCi",
   "collapsed_sections": [
    "Mk8uEpK5m2qy",
    "7df7RA888_KV"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
