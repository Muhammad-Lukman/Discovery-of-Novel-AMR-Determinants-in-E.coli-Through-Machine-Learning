{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KyotJCISWp6"
   },
   "source": [
    "# **Novel Genes-Only Model Without Lineage Marker Filtering**\n",
    "\n",
    "\n",
    "**`Author:`** AMR Prediction Project\n",
    "**`Date:`** December 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5wia1WvSo06"
   },
   "source": [
    "## **SETUP AND IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_HKjKnISmES"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import warnings\n",
    "import json\n",
    "import requests\n",
    "from io import StringIO\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#machine learning\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import (train_test_split, StratifiedKFold,\n",
    "                                      cross_val_score)\n",
    "from sklearn.metrics import (roc_auc_score, roc_curve, auc,\n",
    "                              precision_recall_curve, average_precision_score,\n",
    "                              classification_report, confusion_matrix,\n",
    "                              precision_score, recall_score, f1_score)\n",
    "\n",
    "#statistical tests\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr, chi2_contingency, mannwhitneyu\n",
    "import shap\n",
    "\n",
    "#set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27953,
     "status": "ok",
     "timestamp": 1765993456486,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "MsZytMJ8SuCR",
    "outputId": "fbec7bb9-974f-4f65-c313-8cbf09d4827f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPNdCmt3S2D6"
   },
   "outputs": [],
   "source": [
    "#set paths\n",
    "BASE_DIR = Path('/content/drive/MyDrive')\n",
    "DATA_DIR = BASE_DIR / 'amr_features'\n",
    "ROARY_DIR = BASE_DIR / 'pangenome_features'\n",
    "RESULTS_DIR = BASE_DIR / 'results' / 'additional_experiments'\n",
    "MODEL_DIR = BASE_DIR / 'models'\n",
    "\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1765907641553,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "pnhdc0ELTCky",
    "outputId": "8d1088e9-91d1-46e3-ef51-584be89fa4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: /content/drive/MyDrive/results/additional_experiments\n"
     ]
    }
   ],
   "source": [
    "print(f\"Results will be saved to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6c5PuNYTHTJ"
   },
   "source": [
    "## **Helper function for ID standardization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mr4VDDfRTFqx"
   },
   "outputs": [],
   "source": [
    "def standardize_sample_id(sample_id):\n",
    "    sample_id = str(sample_id).strip()\n",
    "    if '#' in sample_id:\n",
    "        return sample_id\n",
    "    parts = sample_id.rsplit('_', 1)\n",
    "    return f\"{parts[0]}#{parts[1]}\" if len(parts) == 2 else sample_id\n",
    "\n",
    "def fix_sample_ids(df):\n",
    "    df.index = df.index.map(standardize_sample_id)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFJ2AYJmTLnx"
   },
   "source": [
    "## **NOVEL GENES-ONLY MODEL**\n",
    "**`Purpose:`** Test if novel genes alone can predict resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFq2Eia0Tt9Q"
   },
   "outputs": [],
   "source": [
    "def train_novel_genes_only_model(drug='AMX'):\n",
    "    \"\"\"\n",
    "    Train model using ONLY novel genes (no Tier 2)\n",
    "    Tests independent predictive power of novel genes\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Novel Genes-Only Model for {drug}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    #load filtered novel genes\n",
    "    roary_file = ROARY_DIR / f'roary_filtered_{drug}_top500_decorrelated_v2.csv'\n",
    "\n",
    "    if not roary_file.exists():\n",
    "        print(f\"File not found: {roary_file}\")\n",
    "        return None\n",
    "\n",
    "    roary_df = pd.read_csv(roary_file, index_col=0)\n",
    "    roary_df = fix_sample_ids(roary_df)\n",
    "\n",
    "    #load phenotypes\n",
    "    phenotypes = pd.read_csv(BASE_DIR / 'data/E.coli/phenotypic.csv')\n",
    "    if 'Isolate' in phenotypes.columns:\n",
    "        phenotypes = phenotypes.set_index('Isolate')\n",
    "    elif 'Lane.accession' in phenotypes.columns:\n",
    "        phenotypes = phenotypes.set_index('Lane.accession')\n",
    "    phenotypes = fix_sample_ids(phenotypes)\n",
    "\n",
    "    #align samples\n",
    "    common_samples = roary_df.index.intersection(phenotypes.index)\n",
    "    X = roary_df.loc[common_samples]\n",
    "    y = phenotypes.loc[common_samples, drug].map({'R': 1, 'S': 0, 'I': 0}).dropna()\n",
    "    X = X.loc[y.index]\n",
    "\n",
    "    print(f\"Data prepared:\")\n",
    "    print(f\"  Samples: {len(X)}\")\n",
    "    print(f\"  Features (novel genes only): {X.shape[1]}\")\n",
    "    print(f\"  Resistant: {(y==1).sum()} ({(y==1).sum()/len(y)*100:.1f}%)\")\n",
    "    print(f\"  Susceptible: {(y==0).sum()} ({(y==0).sum()/len(y)*100:.1f}%)\")\n",
    "\n",
    "    #train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    #calculate class weight\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "    print(f\"\\nTraining configuration:\")\n",
    "    print(f\"  Train: {len(X_train)} samples\")\n",
    "    print(f\"  Test: {len(X_test)} samples\")\n",
    "    print(f\"  scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "    #train model\n",
    "    model = XGBClassifier(\n",
    "        max_depth=5,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        eval_metric='auc',\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #evaluate\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "    auprc = average_precision_score(y_test, y_pred_proba)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    #cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "\n",
    "    print(f\"PERFORMANCE (NOVEL GENES ONLY)\")\n",
    "    print(f\"AUROC:     {auroc:.4f}\")\n",
    "    print(f\"AUPRC:     {auprc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"\\n5-Fold CV: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['S', 'R'],\n",
    "                                zero_division=0))\n",
    "\n",
    "    #SHAP analysis\n",
    "    print(f\"\\nComputing SHAP values for top features...\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'shap_importance': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values('shap_importance', ascending=False)\n",
    "\n",
    "    print(f\"\\nTop 10 Novel Genes:\")\n",
    "    print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "    #save results\n",
    "    results = {\n",
    "        'drug': drug,\n",
    "        'model_type': 'Novel_Genes_Only',\n",
    "        'n_features': X.shape[1],\n",
    "        'n_samples': len(X),\n",
    "        'auroc': auroc,\n",
    "        'auprc': auprc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std()\n",
    "    }\n",
    "\n",
    "    #save predictions for statistical testing\n",
    "    np.save(RESULTS_DIR / f'novel_only_{drug}_predictions.npy', y_pred_proba)\n",
    "    np.save(RESULTS_DIR / f'novel_only_{drug}_y_test.npy', y_test.values)\n",
    "\n",
    "    #save feature importance\n",
    "    feature_importance.to_csv(\n",
    "        RESULTS_DIR / f'novel_only_feature_importance_{drug}.csv',\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    return results, model, feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24120,
     "status": "ok",
     "timestamp": 1765907922794,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "LWbROy-OT6Nw",
    "outputId": "34932d11-b460-4637-fe57-64a048ff88f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Novel Genes-Only Model for AMX\n",
      "============================================================\n",
      "Data prepared:\n",
      "  Samples: 1089\n",
      "  Features (novel genes only): 489\n",
      "  Resistant: 659 (60.5%)\n",
      "  Susceptible: 430 (39.5%)\n",
      "\n",
      "Training configuration:\n",
      "  Train: 871 samples\n",
      "  Test: 218 samples\n",
      "  scale_pos_weight: 0.65\n",
      "PERFORMANCE (NOVEL GENES ONLY)\n",
      "AUROC:     0.8878\n",
      "AUPRC:     0.9394\n",
      "Precision: 0.9364\n",
      "Recall:    0.7803\n",
      "F1 Score:  0.8512\n",
      "\n",
      "5-Fold CV: 0.9176 ± 0.0146\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.73      0.92      0.81        86\n",
      "           R       0.94      0.78      0.85       132\n",
      "\n",
      "    accuracy                           0.83       218\n",
      "   macro avg       0.83      0.85      0.83       218\n",
      "weighted avg       0.86      0.83      0.84       218\n",
      "\n",
      "\n",
      "Computing SHAP values for top features...\n",
      "\n",
      "Top 10 Novel Genes:\n",
      "    feature  shap_importance\n",
      "       tnpR         1.550910\n",
      " group_3326         0.415631\n",
      "        neo         0.238619\n",
      "group_14256         0.157669\n",
      " group_8657         0.157008\n",
      "group_16388         0.150833\n",
      " group_3820         0.145918\n",
      "group_11074         0.143477\n",
      "       ybeT         0.141375\n",
      "     yhjK_2         0.133024\n",
      "\n",
      "============================================================\n",
      "Training Novel Genes-Only Model for AMC\n",
      "============================================================\n",
      "Data prepared:\n",
      "  Samples: 1089\n",
      "  Features (novel genes only): 489\n",
      "  Resistant: 325 (29.8%)\n",
      "  Susceptible: 764 (70.2%)\n",
      "\n",
      "Training configuration:\n",
      "  Train: 871 samples\n",
      "  Test: 218 samples\n",
      "  scale_pos_weight: 2.35\n",
      "PERFORMANCE (NOVEL GENES ONLY)\n",
      "AUROC:     0.8245\n",
      "AUPRC:     0.6696\n",
      "Precision: 0.5789\n",
      "Recall:    0.6769\n",
      "F1 Score:  0.6241\n",
      "\n",
      "5-Fold CV: 0.8225 ± 0.0403\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.85      0.79      0.82       153\n",
      "           R       0.58      0.68      0.62        65\n",
      "\n",
      "    accuracy                           0.76       218\n",
      "   macro avg       0.72      0.73      0.72       218\n",
      "weighted avg       0.77      0.76      0.76       218\n",
      "\n",
      "\n",
      "Computing SHAP values for top features...\n",
      "\n",
      "Top 10 Novel Genes:\n",
      "    feature  shap_importance\n",
      "       tnpR         0.644598\n",
      " group_3326         0.290800\n",
      "     insA_1         0.252436\n",
      "       nmpC         0.156913\n",
      "       wcaM         0.154614\n",
      "       neuC         0.153986\n",
      "group_14300         0.152238\n",
      "group_24688         0.150698\n",
      "group_26087         0.128955\n",
      "       intI         0.118546\n",
      "\n",
      "============================================================\n",
      "Training Novel Genes-Only Model for CIP\n",
      "============================================================\n",
      "Data prepared:\n",
      "  Samples: 1089\n",
      "  Features (novel genes only): 495\n",
      "  Resistant: 181 (16.6%)\n",
      "  Susceptible: 908 (83.4%)\n",
      "\n",
      "Training configuration:\n",
      "  Train: 871 samples\n",
      "  Test: 218 samples\n",
      "  scale_pos_weight: 5.01\n",
      "PERFORMANCE (NOVEL GENES ONLY)\n",
      "AUROC:     0.9657\n",
      "AUPRC:     0.9523\n",
      "Precision: 0.8462\n",
      "Recall:    0.9167\n",
      "F1 Score:  0.8800\n",
      "\n",
      "5-Fold CV: 0.9719 ± 0.0094\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           S       0.98      0.97      0.98       182\n",
      "           R       0.85      0.92      0.88        36\n",
      "\n",
      "    accuracy                           0.96       218\n",
      "   macro avg       0.91      0.94      0.93       218\n",
      "weighted avg       0.96      0.96      0.96       218\n",
      "\n",
      "\n",
      "Computing SHAP values for top features...\n",
      "\n",
      "Top 10 Novel Genes:\n",
      "    feature  shap_importance\n",
      "     yfkN_2         0.509550\n",
      "       chpB         0.462401\n",
      "group_20717         0.458237\n",
      " group_9126         0.383719\n",
      "     yihF_2         0.342897\n",
      "       betU         0.320068\n",
      "         rz         0.283190\n",
      "       pemK         0.263643\n",
      "     ydeH_2         0.262326\n",
      "     ybl149         0.258600\n"
     ]
    }
   ],
   "source": [
    "#run for all drugs\n",
    "novel_only_results = []\n",
    "for drug in ['AMX', 'AMC', 'CIP']:\n",
    "    result = train_novel_genes_only_model(drug)\n",
    "    if result:\n",
    "        novel_only_results.append(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1765907956244,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "VHePUGH1T95w",
    "outputId": "8d809ccc-5fd1-486a-df04-10496d996483"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMMARY: Novel Genes-Only Performance\n",
      "drug       model_type  n_features  n_samples    auroc    auprc  precision   recall       f1  cv_mean   cv_std\n",
      " AMX Novel_Genes_Only         489       1089 0.887773 0.939388   0.936364 0.780303 0.851240 0.917599 0.014611\n",
      " AMC Novel_Genes_Only         489       1089 0.824535 0.669613   0.578947 0.676923 0.624113 0.822472 0.040322\n",
      " CIP Novel_Genes_Only         495       1089 0.965659 0.952289   0.846154 0.916667 0.880000 0.971863 0.009364\n",
      "\n",
      "Results saved to: /content/drive/MyDrive/results/additional_experiments/novel_genes_only_summary.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"SUMMARY: Novel Genes-Only Performance\")\n",
    "#save summary\n",
    "if novel_only_results:\n",
    "    novel_only_df = pd.DataFrame(novel_only_results)\n",
    "    print(novel_only_df.to_string(index=False))\n",
    "    novel_only_df.to_csv(RESULTS_DIR / 'novel_genes_only_summary.csv', index=False)\n",
    "    print(f\"\\nResults saved to: {RESULTS_DIR / 'novel_genes_only_summary.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8l2sAnjJUUfv"
   },
   "source": [
    "## **STATISTICAL SIGNIFICANCE TESTING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdRBdbGhVDVe"
   },
   "source": [
    "### **DeLong Test**\n",
    "DeLong test is a statistical method `used to compare the performance of two binary classification models` by `assessing if the difference between their` Area Under the Receiver Operating Characteristic (`ROC`) Curves (AUCs) is statistically significant, especially useful for correlated ROCs like those from nested models.\n",
    "- It `helps` determine `if one model genuinely outperforms another`, yielding a p-value to decide if the observed difference isn't just due to chance, making it vital for model selection in machine learning and diagnostics.\n",
    "**`How it works:`**\n",
    "- **`Compares AUCs:`** It calculates the difference between the AUCs of two models.\n",
    "- **`Tests Significance:`** It computes the standard error for this difference and uses it to find a p-value.\n",
    "- **`Interprets Results:`** A small p-value (e.g., < 0.05) suggests a significant performance difference, meaning one model is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgO8ULnWU_o-"
   },
   "outputs": [],
   "source": [
    "def delong_test(y_true, y_pred1, y_pred2, n_bootstraps=2000):\n",
    "    \"\"\"\n",
    "    Bootstrap implementation of DeLong test for comparing two AUROCs\n",
    "\n",
    "    Returns: (difference, p_value, ci_lower, ci_upper)\n",
    "    \"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred1 = np.array(y_pred1)\n",
    "    y_pred2 = np.array(y_pred2)\n",
    "\n",
    "    #original AUROCs\n",
    "    auc1 = roc_auc_score(y_true, y_pred1)\n",
    "    auc2 = roc_auc_score(y_true, y_pred2)\n",
    "    observed_diff = auc2 - auc1\n",
    "\n",
    "    #bootstrap\n",
    "    bootstrap_diffs = []\n",
    "    n_samples = len(y_true)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "\n",
    "        y_boot = y_true[indices]\n",
    "        pred1_boot = y_pred1[indices]\n",
    "        pred2_boot = y_pred2[indices]\n",
    "\n",
    "        try:\n",
    "            auc1_boot = roc_auc_score(y_boot, pred1_boot)\n",
    "            auc2_boot = roc_auc_score(y_boot, pred2_boot)\n",
    "            bootstrap_diffs.append(auc2_boot - auc1_boot)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    bootstrap_diffs = np.array(bootstrap_diffs)\n",
    "\n",
    "    #two-tailed p-value\n",
    "    p_value = 2 * min(\n",
    "        np.mean(bootstrap_diffs <= 0),\n",
    "        np.mean(bootstrap_diffs >= 0)\n",
    "    )\n",
    "\n",
    "    #95% confidence interval\n",
    "    ci_lower = np.percentile(bootstrap_diffs, 2.5)\n",
    "    ci_upper = np.percentile(bootstrap_diffs, 97.5)\n",
    "\n",
    "    return observed_diff, p_value, ci_lower, ci_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7mMBlVnWZtM"
   },
   "source": [
    "### **`McNemar Test`**\n",
    "A Statistical Test for Paired Dichotomous DataThe McNemar test is a **non-parametric statistical test** for **paired dichotomous data**, used to see if there's a **significant change in proportions** between two related groups (like before/after treatment or matched pairs). It focuses on the **discordant pairs** (where one result changed, e.g., 'yes' to 'no') in a 2x2 table (cells 'b' and 'c') to check for **marginal homogeneity**, essentially testing if the proportions in the 'before' and 'after' categories are the same.\n",
    "\n",
    "**`How it Works (The 2x2 Table)`**\n",
    "\n",
    "Imagine a table for 'Before' vs. 'After' a treatment:\n",
    "\n",
    "|  | After: Yes | After: No |\n",
    "| --- | --- | --- |\n",
    "| **Before: Yes** | a (Yes/Yes) | c (Yes/No) |\n",
    "| **Before: No** | b (No/Yes) | d (No/No) |\n",
    "\n",
    "\n",
    "- **a & d:** **Concordant pairs** (no change).\n",
    "- **b & c:** **Discordant pairs** (change occurred).\n",
    "\n",
    "The test focuses on **b** and **c**, the changes, to see if the number of 'Yes' to 'No' changes (**c**) is different from 'No' to 'Yes' changes (**b**).\n",
    "\n",
    "When to Use It* **Before-and-After Studies:** Same subjects measured twice (e.g., opinion on a policy before and after an event).\n",
    "- **Matched-Pairs Studies:** Similar individuals exposed to different conditions (e.g., comparing two diagnostic tests on the same patients)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fJzYi6vVuAV"
   },
   "outputs": [],
   "source": [
    "def mcnemar_test(y_true, y_pred1, y_pred2):\n",
    "    \"\"\"\n",
    "    McNemar's test for comparing two classifiers\n",
    "    Tests if error rates are significantly different\n",
    "    \"\"\"\n",
    "    from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "    #convert probabilities to binary predictions if needed\n",
    "    if y_pred1.dtype == float:\n",
    "        y_pred1 = (y_pred1 > 0.5).astype(int)\n",
    "    if y_pred2.dtype == float:\n",
    "        y_pred2 = (y_pred2 > 0.5).astype(int)\n",
    "\n",
    "    #create contingency table\n",
    "    #both correct, model1 wrong model2 correct, model1 correct model2 wrong, both wrong\n",
    "    both_correct = np.sum((y_pred1 == y_true) & (y_pred2 == y_true))\n",
    "    model1_wrong_model2_correct = np.sum((y_pred1 != y_true) & (y_pred2 == y_true))\n",
    "    model1_correct_model2_wrong = np.sum((y_pred1 == y_true) & (y_pred2 != y_true))\n",
    "    both_wrong = np.sum((y_pred1 != y_true) & (y_pred2 != y_true))\n",
    "\n",
    "    #McNemar's test uses the discordant pairs\n",
    "    contingency = np.array([[both_correct, model1_correct_model2_wrong],\n",
    "                            [model1_wrong_model2_correct, both_wrong]])\n",
    "\n",
    "    result = mcnemar(contingency, exact=False, correction=True)\n",
    "\n",
    "    return result.statistic, result.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alRV8lyhWvwU"
   },
   "outputs": [],
   "source": [
    "def compare_all_models():\n",
    "    \"\"\"\n",
    "    Compare Tier 1, Tier 2, Tier 3, and Novel-Only models\n",
    "    \"\"\"\n",
    "    print(\"\\nComparing All Model Tiers...\")\n",
    "    print(\"Note: This requires predictions saved from previous training runs\")\n",
    "\n",
    "    all_comparisons = []\n",
    "\n",
    "    for drug in ['AMX', 'AMC', 'CIP']:\n",
    "        print(f\"\\n{drug}:\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        try:\n",
    "            #load predictions (we need to save these during model training) (we lost the data accidently)\n",
    "            tier2_pred_file = RESULTS_DIR / f'../tier2_{drug}_predictions.npy'\n",
    "            tier3_pred_file = RESULTS_DIR / f'../tier3_{drug}_predictions.npy'\n",
    "            novel_pred_file = RESULTS_DIR / f'novel_only_{drug}_predictions.npy'\n",
    "            y_test_file = RESULTS_DIR / f'novel_only_{drug}_y_test.npy'\n",
    "\n",
    "            if not all([f.exists() for f in [novel_pred_file, y_test_file]]):\n",
    "                print(f\"  Missing prediction files. Run models first and save predictions.\")\n",
    "                print(f\"     np.save(RESULTS_DIR / 'tier2_{drug}_predictions.npy', y_pred_proba)\")\n",
    "                continue\n",
    "\n",
    "            y_true = np.load(y_test_file)\n",
    "            novel_pred = np.load(novel_pred_file)\n",
    "\n",
    "            # If Tier 2 and Tier 3 predictions exist\n",
    "            if tier2_pred_file.exists() and tier3_pred_file.exists():\n",
    "                tier2_pred = np.load(tier2_pred_file)\n",
    "                tier3_pred = np.load(tier3_pred_file)\n",
    "\n",
    "                #tier 2 vs Tier 3\n",
    "                diff_23, p_23, ci_low_23, ci_high_23 = delong_test(\n",
    "                    y_true, tier2_pred, tier3_pred\n",
    "                )\n",
    "\n",
    "                sig_23 = '***' if p_23 < 0.001 else '**' if p_23 < 0.01 else '*' if p_23 < 0.05 else 'ns'\n",
    "\n",
    "                print(f\"  Tier 2 vs Tier 3:\")\n",
    "                print(f\"    ΔAUROC = {diff_23:+.4f}, p = {p_23:.4f} {sig_23}\")\n",
    "                print(f\"    95% CI: [{ci_low_23:.4f}, {ci_high_23:.4f}]\")\n",
    "\n",
    "                all_comparisons.append({\n",
    "                    'drug': drug,\n",
    "                    'comparison': 'Tier2 vs Tier3',\n",
    "                    'delta_auroc': diff_23,\n",
    "                    'p_value': p_23,\n",
    "                    'ci_lower': ci_low_23,\n",
    "                    'ci_upper': ci_high_23,\n",
    "                    'significant': sig_23\n",
    "                })\n",
    "\n",
    "                #tier 3 vs Novel-Only\n",
    "                diff_3n, p_3n, ci_low_3n, ci_high_3n = delong_test(\n",
    "                    y_true, tier3_pred, novel_pred\n",
    "                )\n",
    "\n",
    "                sig_3n = '***' if p_3n < 0.001 else '**' if p_3n < 0.01 else '*' if p_3n < 0.05 else 'ns'\n",
    "\n",
    "                print(f\"  Tier 3 vs Novel-Only:\")\n",
    "                print(f\"    ΔAUROC = {diff_3n:+.4f}, p = {p_3n:.4f} {sig_3n}\")\n",
    "                print(f\"    95% CI: [{ci_low_3n:.4f}, {ci_high_3n:.4f}]\")\n",
    "\n",
    "                all_comparisons.append({\n",
    "                    'drug': drug,\n",
    "                    'comparison': 'Tier3 vs NovelOnly',\n",
    "                    'delta_auroc': diff_3n,\n",
    "                    'p_value': p_3n,\n",
    "                    'ci_lower': ci_low_3n,\n",
    "                    'ci_upper': ci_high_3n,\n",
    "                    'significant': sig_3n\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "            continue\n",
    "\n",
    "    if all_comparisons:\n",
    "        comparison_df = pd.DataFrame(all_comparisons)\n",
    "        comparison_df.to_csv(RESULTS_DIR / 'statistical_comparisons.csv', index=False)\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STATISTICAL COMPARISON SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        print(comparison_df.to_string(index=False))\n",
    "        print(f\"\\nSaved to: {RESULTS_DIR / 'statistical_comparisons.csv'}\")\n",
    "\n",
    "        return comparison_df\n",
    "    else:\n",
    "        print(\"\\nNo comparisons performed. Save predictions during training:\")\n",
    "        print(\"   np.save(RESULTS_DIR / 'tier2_{drug}_predictions.npy', y_pred_proba)\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1765909836614,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "WESIK_FJbMpj",
    "outputId": "1df876a9-e013-48fb-e57b-2f9d545557e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing All Model Tiers...\n",
      "Note: This requires predictions saved from previous training runs\n",
      "\n",
      "AMX:\n",
      "------------------------------------------------------------\n",
      "\n",
      "AMC:\n",
      "------------------------------------------------------------\n",
      "\n",
      "CIP:\n",
      "------------------------------------------------------------\n",
      "\n",
      "No comparisons performed. Save predictions during training:\n",
      "   np.save(RESULTS_DIR / 'tier2_{drug}_predictions.npy', y_pred_proba)\n"
     ]
    }
   ],
   "source": [
    "#run statistical tests\n",
    "stat_results = compare_all_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhJR7-20bo8z"
   },
   "source": [
    "## **FEATURE INTERACTION ANALYSIS**\n",
    " SHAP interaction values to find synergistic gene pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fFpDJO09b6ry"
   },
   "outputs": [],
   "source": [
    "def analyze_feature_interactions(drug='AMX', top_n=20):\n",
    "    \"\"\"\n",
    "    Detect important feature interactions using SHAP interaction values\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing Feature Interactions for {drug}\")\n",
    "\n",
    "    #load Tier 3 data\n",
    "    tier2 = pd.read_csv(DATA_DIR / 'tier2_amr_genes_plus_mutations.csv', index_col=0)\n",
    "    tier2 = fix_sample_ids(tier2)\n",
    "\n",
    "    roary_file = ROARY_DIR / f'roary_filtered_{drug}_top500_decorrelated_v2.csv'\n",
    "    if not roary_file.exists():\n",
    "        print(f\"File not found: {roary_file}\")\n",
    "        return None\n",
    "\n",
    "    roary = pd.read_csv(roary_file, index_col=0)\n",
    "    roary = fix_sample_ids(roary)\n",
    "\n",
    "    tier3 = pd.concat([tier2, roary], axis=1, join='inner')\n",
    "\n",
    "    #load phenotypes\n",
    "    phenotypes = pd.read_csv(BASE_DIR / 'data/E.coli/phenotypic.csv')\n",
    "    if 'Isolate' in phenotypes.columns:\n",
    "        phenotypes = phenotypes.set_index('Isolate')\n",
    "    phenotypes = fix_sample_ids(phenotypes)\n",
    "\n",
    "    #prepare data\n",
    "    common_samples = tier3.index.intersection(phenotypes.index)\n",
    "    X = tier3.loc[common_samples]\n",
    "    y = phenotypes.loc[common_samples, drug].map({'R': 1, 'S': 0, 'I': 0}).dropna()\n",
    "    X = X.loc[y.index]\n",
    "\n",
    "    # Train a quick model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        max_depth=5,\n",
    "        n_estimators=100,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Computing SHAP interaction values...\")\n",
    "    print(f\"  (Using sample of {min(100, len(X_test))} test samples for efficiency)\")\n",
    "\n",
    "    #sample subset for computational efficiency\n",
    "    sample_size = min(100, len(X_test))\n",
    "    sample_indices = np.random.choice(len(X_test), size=sample_size, replace=False)\n",
    "    X_sample = X_test.iloc[sample_indices]\n",
    "\n",
    "    # SHAP interaction values\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_interaction = explainer.shap_interaction_values(X_sample)\n",
    "\n",
    "    # Find top interactions\n",
    "    mean_abs_interaction = np.abs(shap_interaction).mean(axis=0)\n",
    "\n",
    "    #get upper triangle (avoid duplicates: i < j)\n",
    "    interactions = []\n",
    "    n_features = mean_abs_interaction.shape[0]\n",
    "\n",
    "    for i in range(n_features):\n",
    "        for j in range(i+1, n_features):\n",
    "            interactions.append({\n",
    "                'feature1': X.columns[i],\n",
    "                'feature2': X.columns[j],\n",
    "                'interaction_score': mean_abs_interaction[i, j],\n",
    "                'feature1_type': 'Novel' if X.columns[i] in roary.columns else 'Tier2',\n",
    "                'feature2_type': 'Novel' if X.columns[j] in roary.columns else 'Tier2'\n",
    "            })\n",
    "\n",
    "    #sort by interaction score\n",
    "    interactions_df = pd.DataFrame(interactions)\n",
    "    interactions_df = interactions_df.sort_values('interaction_score', ascending=False)\n",
    "\n",
    "    print(f\"\\nTop {top_n} Feature Interactions:\")\n",
    "    print(interactions_df.head(top_n).to_string(index=False))\n",
    "\n",
    "    #save\n",
    "    interactions_df.to_csv(\n",
    "        RESULTS_DIR / f'feature_interactions_{drug}.csv',\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"\\nSaved to: {RESULTS_DIR / f'feature_interactions_{drug}.csv'}\")\n",
    "\n",
    "    #analyze interaction types\n",
    "    print(f\"\\nInteraction Type Distribution (Top {top_n}):\")\n",
    "    top_interactions = interactions_df.head(top_n)\n",
    "\n",
    "    tier2_tier2 = len(top_interactions[\n",
    "        (top_interactions['feature1_type'] == 'Tier2') &\n",
    "        (top_interactions['feature2_type'] == 'Tier2')\n",
    "    ])\n",
    "\n",
    "    novel_novel = len(top_interactions[\n",
    "        (top_interactions['feature1_type'] == 'Novel') &\n",
    "        (top_interactions['feature2_type'] == 'Novel')\n",
    "    ])\n",
    "\n",
    "    tier2_novel = top_n - tier2_tier2 - novel_novel\n",
    "\n",
    "    print(f\"  Tier2 × Tier2: {tier2_tier2}\")\n",
    "    print(f\"  Novel × Novel: {novel_novel}\")\n",
    "    print(f\"  Tier2 × Novel: {tier2_novel}\")\n",
    "\n",
    "    return interactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 516023,
     "status": "ok",
     "timestamp": 1765910522779,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "zzch9qfYcDYa",
    "outputId": "a166a7a6-81f1-4e27-bc75-bc99a2a81b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running interaction analysis for all drugs...\n",
      "Analyzing Feature Interactions for AMX\n",
      "Computing SHAP interaction values...\n",
      "  (Using sample of 100 test samples for efficiency)\n",
      "\n",
      "Top 20 Feature Interactions:\n",
      "   feature1    feature2  interaction_score feature1_type feature2_type\n",
      "      TEM-4 group_26397           0.107106         Tier2         Novel\n",
      "      OXA-1       TEM-4           0.086660         Tier2         Tier2\n",
      " ftsI_L192F        yehM           0.071380         Tier2         Novel\n",
      " ompC_Q196E        yedE           0.064727         Tier2         Novel\n",
      "      TEM-4        sul1           0.054207         Tier2         Tier2\n",
      " ompC_Q196E        sopA           0.052433         Tier2         Novel\n",
      "      TEM-4 group_11074           0.052408         Tier2         Novel\n",
      "      TEM-4  group_3820           0.051904         Tier2         Novel\n",
      "       tnpR      yhjK_2           0.044986         Novel         Novel\n",
      " gyrA_P215T       TEM-4           0.044978         Tier2         Tier2\n",
      " ompC_G133R group_11074           0.043596         Tier2         Novel\n",
      "      TEM-4        ybeT           0.040321         Tier2         Novel\n",
      "group_16694        betU           0.038501         Novel         Novel\n",
      "      TEM-4      yhjK_2           0.038150         Tier2         Novel\n",
      "      TEM-4 group_14256           0.037271         Tier2         Novel\n",
      "       cyaA group_16687           0.033674         Novel         Novel\n",
      "      TEM-4        yhjV           0.033466         Tier2         Novel\n",
      "   blaTEM-1 group_11074           0.033205         Tier2         Novel\n",
      "      blaEC  group_9728           0.032449         Tier2         Novel\n",
      "      TEM-4  group_7221           0.032387         Tier2         Novel\n",
      "\n",
      "Saved to: /content/drive/MyDrive/results/additional_experiments/feature_interactions_AMX.csv\n",
      "\n",
      "Interaction Type Distribution (Top 20):\n",
      "  Tier2 × Tier2: 3\n",
      "  Novel × Novel: 3\n",
      "  Tier2 × Novel: 14\n",
      "Analyzing Feature Interactions for AMC\n",
      "Computing SHAP interaction values...\n",
      "  (Using sample of 100 test samples for efficiency)\n",
      "\n",
      "Top 20 Feature Interactions:\n",
      "   feature1    feature2  interaction_score feature1_type feature2_type\n",
      "      TEM-4    blaTEM-1           0.304413         Tier2         Tier2\n",
      "      TEM-4    blaOXA-1           0.170445         Tier2         Tier2\n",
      "      TEM-4  group_7221           0.110498         Tier2         Novel\n",
      " gyrA_T654S       TEM-4           0.064161         Tier2         Tier2\n",
      " parE_G197C       TEM-4           0.063225         Tier2         Tier2\n",
      "   blaOXA-1 group_27188           0.043085         Tier2         Novel\n",
      "      TEM-4  group_9002           0.042557         Tier2         Novel\n",
      " parC_G107C        mdtM           0.042198         Tier2         Tier2\n",
      " group_7896  group_5988           0.042191         Novel         Novel\n",
      "      TEM-4 group_24688           0.041136         Tier2         Novel\n",
      "      TEM-4   group_312           0.039042         Tier2         Novel\n",
      "       tnpR group_17656           0.038750         Novel         Novel\n",
      " ompC_G362R       TEM-4           0.038332         Tier2         Tier2\n",
      "      TEM-4        yfeA           0.037564         Tier2         Novel\n",
      " group_7221      ydeH_2           0.037498         Novel         Novel\n",
      "      TEM-4  group_5884           0.036340         Tier2         Novel\n",
      " group_2853  group_9500           0.035895         Novel         Novel\n",
      "      TEM-4 group_16694           0.034748         Tier2         Novel\n",
      " gyrA_T654S        yfeA           0.033981         Tier2         Novel\n",
      "group_16955 group_16694           0.032537         Novel         Novel\n",
      "\n",
      "Saved to: /content/drive/MyDrive/results/additional_experiments/feature_interactions_AMC.csv\n",
      "\n",
      "Interaction Type Distribution (Top 20):\n",
      "  Tier2 × Tier2: 6\n",
      "  Novel × Novel: 5\n",
      "  Tier2 × Novel: 9\n",
      "Analyzing Feature Interactions for CIP\n",
      "Computing SHAP interaction values...\n",
      "  (Using sample of 100 test samples for efficiency)\n",
      "\n",
      "Top 20 Feature Interactions:\n",
      "  feature1                                 feature2  interaction_score feature1_type feature2_type\n",
      " gyrA_V85F                                gyrA_S83L           1.037913         Tier2         Tier2\n",
      " gyrA_S83L                                     nmpC           0.192859         Tier2         Novel\n",
      " gyrA_S83L                                     yedI           0.173499         Tier2         Novel\n",
      " gyrA_V85F                              group_13316           0.123771         Tier2         Novel\n",
      " gyrA_V85F                                     yedI           0.108332         Tier2         Novel\n",
      " gyrA_V85F                                     nmpC           0.102188         Tier2         Novel\n",
      "ompC_G133R                                       rz           0.076310         Tier2         Novel\n",
      " gyrA_S83L                                folP_E73A           0.073225         Tier2         Tier2\n",
      " gyrA_V85F                                   yaiO_1           0.065538         Tier2         Novel\n",
      " gyrA_S83L                                     gatD           0.063452         Tier2         Novel\n",
      " gyrA_V85F                                phoP_G53*           0.062956         Tier2         Tier2\n",
      "gyrA_I198L                                gyrA_V85F           0.060104         Tier2         Tier2\n",
      " gyrA_S83L                                   yaiO_1           0.049870         Tier2         Novel\n",
      " gyrA_S83L phoP_frameshift_insertion_1bp_pos1189670           0.048110         Tier2         Tier2\n",
      " gyrA_S83L                                       rz           0.043911         Tier2         Novel\n",
      " gyrA_S83L                                     ybcQ           0.037264         Tier2         Novel\n",
      " gyrA_S83L                              group_12513           0.036607         Tier2         Novel\n",
      " gyrA_V85F                                 folP_F4Y           0.035686         Tier2         Tier2\n",
      " gyrA_V85F                                folP_E73A           0.033890         Tier2         Tier2\n",
      "      yedI                                     nmpC           0.033097         Novel         Novel\n",
      "\n",
      "Saved to: /content/drive/MyDrive/results/additional_experiments/feature_interactions_CIP.csv\n",
      "\n",
      "Interaction Type Distribution (Top 20):\n",
      "  Tier2 × Tier2: 7\n",
      "  Novel × Novel: 1\n",
      "  Tier2 × Novel: 12\n"
     ]
    }
   ],
   "source": [
    "#run for all drugs\n",
    "print(\"\\nRunning interaction analysis for all drugs...\")\n",
    "for drug in ['AMX', 'AMC', 'CIP']:\n",
    "    analyze_feature_interactions(drug, top_n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUab1ATTYV8e"
   },
   "source": [
    "# **Novel Genes-Only Model With Lineage Marker Filter**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14652,
     "status": "ok",
     "timestamp": 1765993001911,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "aEdIo0l-YZ9v",
    "outputId": "11568457-2300-41f6-b823-3059b78979b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting biopython\n",
      "  Downloading biopython-1.86-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (2.0.2)\n",
      "Downloading biopython-1.86-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: biopython\n",
      "Successfully installed biopython-1.86\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from pathlib import Path\n",
    "try:\n",
    "  from Bio import SeqIO, Entrez\n",
    "except:\n",
    "  !pip install biopython\n",
    "  from Bio import SeqIO, Entrez\n",
    "from xml.etree import ElementTree as ET\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R07U3DOTYsC7"
   },
   "outputs": [],
   "source": [
    "BASE_DIR = Path('/content/drive/MyDrive')\n",
    "RESULTS_DIR = BASE_DIR / 'results' / 'additional_experiments'\n",
    "DATA_DIR = BASE_DIR / 'data' / 'E.coli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pwjYNZPoZs66"
   },
   "outputs": [],
   "source": [
    "def train_novel_genes_filtered(drug='AMX'):\n",
    "    \"\"\"\n",
    "    Train novel genes-only model WITH lineage marker filtering\n",
    "    This matches Tier 3 filtering\n",
    "    \"\"\"\n",
    "    from scipy.stats import pearsonr\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "    import shap\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Novel Genes-Only Model (WITH Lineage Filter) - {drug}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # Helper function\n",
    "    def standardize_sample_id(sample_id):\n",
    "        sample_id = str(sample_id).strip()\n",
    "        if '#' in sample_id:\n",
    "            return sample_id\n",
    "        parts = sample_id.rsplit('_', 1)\n",
    "        return f\"{parts[0]}#{parts[1]}\" if len(parts) == 2 else sample_id\n",
    "\n",
    "    def fix_sample_ids(df):\n",
    "        df.index = df.index.map(standardize_sample_id)\n",
    "        return df\n",
    "\n",
    "    #load data\n",
    "    roary_file = BASE_DIR / 'pangenome_features' / f'roary_filtered_{drug}_top500_decorrelated_v2.csv'\n",
    "    roary_df = pd.read_csv(roary_file, index_col=0)\n",
    "    roary_df = fix_sample_ids(roary_df)\n",
    "\n",
    "    #load Tier 2 for lineage marker filtering\n",
    "    tier2_file = BASE_DIR / 'amr_features' / 'tier2_amr_genes_plus_mutations.csv'\n",
    "    tier2_df = pd.read_csv(tier2_file, index_col=0)\n",
    "    tier2_df = fix_sample_ids(tier2_df)\n",
    "\n",
    "    print(f\"Loaded data:\")\n",
    "    print(f\"  Roary genes: {roary_df.shape}\")\n",
    "    print(f\"  Tier 2 (for filtering): {tier2_df.shape}\")\n",
    "\n",
    "    #apply lineage marker filter (ρ ≥ 0.70)\n",
    "    print(f\"\\nApplying lineage marker filter (ρ ≥ 0.70)...\")\n",
    "\n",
    "    potential_markers = ['rz', 'yedI', 'nmpC', 'gatD', 'betU', 'yeeO']\n",
    "\n",
    "    genes_to_keep = []\n",
    "    removed_genes = []\n",
    "\n",
    "    for gene in roary_df.columns:\n",
    "        if gene in potential_markers:\n",
    "            removed_genes.append(gene)\n",
    "            continue\n",
    "\n",
    "        #check correlation with Tier 2 features\n",
    "        max_corr = 0\n",
    "        for tier2_feature in tier2_df.columns:\n",
    "            try:\n",
    "                corr, _ = pearsonr(roary_df[gene], tier2_df[tier2_feature])\n",
    "                max_corr = max(max_corr, abs(corr))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if max_corr < 0.7:\n",
    "            genes_to_keep.append(gene)\n",
    "        else:\n",
    "            removed_genes.append(gene)\n",
    "\n",
    "    print(f\"  Kept: {len(genes_to_keep)} genes\")\n",
    "    print(f\"  Removed: {len(removed_genes)} genes (lineage markers)\")\n",
    "    print(f\"  Removed genes: {removed_genes[:10]}...\")\n",
    "\n",
    "    roary_filtered = roary_df[genes_to_keep]\n",
    "\n",
    "    #load phenotypes\n",
    "    phenotypes = pd.read_csv(DATA_DIR / 'phenotypic.csv')\n",
    "    if 'Isolate' in phenotypes.columns:\n",
    "        phenotypes = phenotypes.set_index('Isolate')\n",
    "    phenotypes = fix_sample_ids(phenotypes)\n",
    "\n",
    "    #align samples\n",
    "    common_samples = roary_filtered.index.intersection(phenotypes.index)\n",
    "    X = roary_filtered.loc[common_samples]\n",
    "    y = phenotypes.loc[common_samples, drug].map({'R': 1, 'S': 0, 'I': 0}).dropna()\n",
    "    X = X.loc[y.index]\n",
    "\n",
    "    print(f\"\\nData prepared:\")\n",
    "    print(f\"  Samples: {len(X)}\")\n",
    "    print(f\"  Features (filtered novel genes): {X.shape[1]}\")\n",
    "    print(f\"  Resistant: {(y==1).sum()} ({(y==1).sum()/len(y)*100:.1f}%)\")\n",
    "\n",
    "    #train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "    #train model\n",
    "    model = XGBClassifier(\n",
    "        max_depth=5,\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        min_child_weight=3,\n",
    "        gamma=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        eval_metric='auc',\n",
    "        verbosity=0\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #evaluate\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "    auprc = average_precision_score(y_test, y_pred_proba)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    #cross-validation\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "\n",
    "    print(f\"PERFORMANCE (FILTERED NOVEL GENES ONLY)\")\n",
    "    print(f\"AUROC:     {auroc:.4f}\")\n",
    "    print(f\"AUPRC:     {auprc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1 Score:  {f1:.4f}\")\n",
    "    print(f\"\\n5-Fold CV: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "\n",
    "    #SHAP analysis\n",
    "    print(f\"\\nComputing SHAP values...\")\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'shap_importance': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values('shap_importance', ascending=False)\n",
    "\n",
    "    print(f\"\\nTop 10 Novel Genes (after lineage filtering):\")\n",
    "    print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "    #save\n",
    "    results = {\n",
    "        'drug': drug,\n",
    "        'model_type': 'Novel_Genes_Filtered',\n",
    "        'n_features': X.shape[1],\n",
    "        'n_features_removed': len(removed_genes),\n",
    "        'n_samples': len(X),\n",
    "        'auroc': auroc,\n",
    "        'auprc': auprc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std()\n",
    "    }\n",
    "\n",
    "    feature_importance.to_csv(\n",
    "        RESULTS_DIR / f'novel_filtered_feature_importance_{drug}.csv',\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    return results, feature_importance, removed_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1061833,
     "status": "ok",
     "timestamp": 1765994537378,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "qhpt_lRHZuha",
    "outputId": "cc284b7d-a89a-4963-d6fe-b809299a9226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING FILTERED NOVEL GENES-ONLY MODELS\n",
      "\n",
      "============================================================\n",
      "Novel Genes-Only Model (WITH Lineage Filter) - AMX\n",
      "============================================================\n",
      "Loaded data:\n",
      "  Roary genes: (1089, 489)\n",
      "  Tier 2 (for filtering): (1089, 1236)\n",
      "\n",
      "Applying lineage marker filter (ρ ≥ 0.70)...\n",
      "  Kept: 179 genes\n",
      "  Removed: 310 genes (lineage markers)\n",
      "  Removed genes: ['tnpR', 'group_8657', 'neo', 'yedA_2', 'group_5885', 'group_17014', 'group_18191', 'group_21010', 'group_15443', 'group_14300']...\n",
      "\n",
      "Data prepared:\n",
      "  Samples: 1089\n",
      "  Features (filtered novel genes): 179\n",
      "  Resistant: 659 (60.5%)\n",
      "PERFORMANCE (FILTERED NOVEL GENES ONLY)\n",
      "AUROC:     0.8623\n",
      "AUPRC:     0.9169\n",
      "Precision: 0.8750\n",
      "Recall:    0.7955\n",
      "F1 Score:  0.8333\n",
      "\n",
      "5-Fold CV: 0.8883 ± 0.0147\n",
      "\n",
      "Computing SHAP values...\n",
      "\n",
      "Top 10 Novel Genes (after lineage filtering):\n",
      "    feature  shap_importance\n",
      " group_3326         1.082576\n",
      "       pemK         0.292495\n",
      "       intI         0.242284\n",
      "       yehM         0.191942\n",
      "group_11074         0.160231\n",
      "group_16687         0.136894\n",
      " group_8890         0.136159\n",
      " group_3820         0.130895\n",
      " group_5999         0.115107\n",
      "     insA_1         0.108666\n",
      "\n",
      "============================================================\n",
      "Novel Genes-Only Model (WITH Lineage Filter) - AMC\n",
      "============================================================\n",
      "Loaded data:\n",
      "  Roary genes: (1089, 489)\n",
      "  Tier 2 (for filtering): (1089, 1236)\n",
      "\n",
      "Applying lineage marker filter (ρ ≥ 0.70)...\n",
      "  Kept: 118 genes\n",
      "  Removed: 371 genes (lineage markers)\n",
      "  Removed genes: ['tnpR', 'group_15883', 'group_21010', 'yjgL_2', 'group_3469', 'group_15621', 'rfbC', 'wbbJ', 'group_15443', 'tnpA_4']...\n",
      "\n",
      "Data prepared:\n",
      "  Samples: 1089\n",
      "  Features (filtered novel genes): 118\n",
      "  Resistant: 325 (29.8%)\n",
      "PERFORMANCE (FILTERED NOVEL GENES ONLY)\n",
      "AUROC:     0.8193\n",
      "AUPRC:     0.6532\n",
      "Precision: 0.6027\n",
      "Recall:    0.6769\n",
      "F1 Score:  0.6377\n",
      "\n",
      "5-Fold CV: 0.7934 ± 0.0486\n",
      "\n",
      "Computing SHAP values...\n",
      "\n",
      "Top 10 Novel Genes (after lineage filtering):\n",
      "    feature  shap_importance\n",
      " group_3326         0.609212\n",
      "     insA_1         0.276231\n",
      "group_20717         0.245894\n",
      "       wcaM         0.176111\n",
      "       tnsB         0.172266\n",
      "      parD1         0.144920\n",
      "       pemK         0.140780\n",
      "group_17656         0.129673\n",
      "       sopA         0.126831\n",
      "       intI         0.122876\n",
      "\n",
      "============================================================\n",
      "Novel Genes-Only Model (WITH Lineage Filter) - CIP\n",
      "============================================================\n",
      "Loaded data:\n",
      "  Roary genes: (1089, 495)\n",
      "  Tier 2 (for filtering): (1089, 1236)\n",
      "\n",
      "Applying lineage marker filter (ρ ≥ 0.70)...\n",
      "  Kept: 88 genes\n",
      "  Removed: 407 genes (lineage markers)\n",
      "  Removed genes: ['group_15883', 'yjgL_2', 'group_17581', 'group_15443', 'yihF_2', 'group_2358', 'group_3733', 'group_21540', 'group_8629', 'gemA']...\n",
      "\n",
      "Data prepared:\n",
      "  Samples: 1089\n",
      "  Features (filtered novel genes): 88\n",
      "  Resistant: 181 (16.6%)\n",
      "PERFORMANCE (FILTERED NOVEL GENES ONLY)\n",
      "AUROC:     0.9402\n",
      "AUPRC:     0.9232\n",
      "Precision: 0.8049\n",
      "Recall:    0.9167\n",
      "F1 Score:  0.8571\n",
      "\n",
      "5-Fold CV: 0.9564 ± 0.0156\n",
      "\n",
      "Computing SHAP values...\n",
      "\n",
      "Top 10 Novel Genes (after lineage filtering):\n",
      "    feature  shap_importance\n",
      " group_9126         0.908839\n",
      "       chpB         0.753290\n",
      "group_20717         0.570555\n",
      "     dmsB_1         0.489351\n",
      "       pemK         0.461025\n",
      "       ybcQ         0.393321\n",
      "group_16337         0.353005\n",
      "       yggM         0.239059\n",
      "group_16890         0.225888\n",
      "       ynbB         0.217477\n"
     ]
    }
   ],
   "source": [
    "#run for all drugs\n",
    "print(\"TRAINING FILTERED NOVEL GENES-ONLY MODELS\")\n",
    "\n",
    "filtered_results = []\n",
    "for drug in ['AMX', 'AMC', 'CIP']:\n",
    "    result = train_novel_genes_filtered(drug)\n",
    "    if result:\n",
    "        filtered_results.append(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1765994537497,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "addH8NH1Z0Fy",
    "outputId": "ad1bc0a9-8a25-4c88-e83b-c228409aa06d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPARISON: Unfiltered vs Filtered Novel Genes\n",
      "Drug      Model    AUROC       F1  N_Features\n",
      " AMX Unfiltered 0.888000 0.851000         489\n",
      " AMC Unfiltered 0.825000 0.624000         489\n",
      " CIP Unfiltered 0.966000 0.880000         495\n",
      " AMX   Filtered 0.862315 0.833333         179\n",
      " AMC   Filtered 0.819256 0.637681         118\n",
      " CIP   Filtered 0.940171 0.857143          88\n"
     ]
    }
   ],
   "source": [
    "#compare with unfiltered\n",
    "print(\"COMPARISON: Unfiltered vs Filtered Novel Genes\")\n",
    "\n",
    "comparison_data = {\n",
    "    'Drug': ['AMX', 'AMC', 'CIP', 'AMX', 'AMC', 'CIP'],\n",
    "    'Model': ['Unfiltered']*3 + ['Filtered']*3,\n",
    "    'AUROC': [0.888, 0.825, 0.966,\n",
    "              filtered_results[0]['auroc'], filtered_results[1]['auroc'], filtered_results[2]['auroc']],\n",
    "    'F1': [0.851, 0.624, 0.880,\n",
    "           filtered_results[0]['f1'], filtered_results[1]['f1'], filtered_results[2]['f1']],\n",
    "    'N_Features': [489, 489, 495,\n",
    "                   filtered_results[0]['n_features'], filtered_results[1]['n_features'], filtered_results[2]['n_features']]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "comparison_df.to_csv(RESULTS_DIR / 'novel_genes_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zNcF9dH8DFFx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPS8RZ1wWWTNtQKDdjzFiCi",
   "collapsed_sections": [
    "Mk8uEpK5m2qy",
    "7df7RA888_KV"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
