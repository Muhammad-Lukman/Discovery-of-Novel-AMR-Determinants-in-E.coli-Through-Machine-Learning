{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVb3YjFXFj4J"
   },
   "source": [
    "# **1. Tier 1A: Acquired AMR Genes (409 features)**\n",
    "**`File:`** `tier1a_acquired_amr_genes_CORRECTED.csv`\n",
    "\n",
    "**`Composition:`**\n",
    "- **CARD**: 143 genes\n",
    "- **ResFinder**: 121 genes\n",
    "- **AMRFinderPlus** (acquired only): 145 genes\n",
    "\n",
    "**`Use:`**\n",
    "- Tier 1 baseline models (`known AMR mechanisms`)\n",
    "- Correlation filtering with roary pangenome to make novel gene set. (DONE)\n",
    "- Feature importance benchmarking\n",
    "\n",
    "These genes are \"`Known resistance determinants`\".\n",
    "\n",
    "A `very Important note` or rather `a mistake to avoid`, we can't and should never use these for Novel gene discovery (`these are known` mechanisms).\n",
    "\n",
    "If you had such thoughts,` SUCH BLASPHEMOUS thoughts!!!` Quickly, Let those thoughts Sho! Sho! and go take a shower with Cold Water..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOPSI3h7McDq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17545,
     "status": "ok",
     "timestamp": 1765218130995,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "dKiZladGMdYr",
    "outputId": "57422830-d9d4-447a-dbe5-45664e3f6428"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJD2PAcHNDiw"
   },
   "source": [
    "## **Load Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86KaOjJ3M0Th"
   },
   "outputs": [],
   "source": [
    "#load Tier 1A\n",
    "tier1a = pd.read_csv('/content/drive/MyDrive/amr_features/tier1a_acquired_amr_genes_CORRECTED.csv', index_col=0)\n",
    "\n",
    "#load phenotypes\n",
    "phenotypes = pd.read_csv('/content/drive/MyDrive/data/E.coli/phenotypic.csv', index_col=0)\n",
    "phenotypes.set_index('Isolate', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttSdJmVxM_WZ"
   },
   "source": [
    "## **Standardize sample IDs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpRlzQ_YM8Zw"
   },
   "outputs": [],
   "source": [
    "def replace_last_underscore_with_hash(s):\n",
    "    s_str = str(s)\n",
    "    parts = s_str.rsplit('_', 1)\n",
    "    return '#'.join(parts) if len(parts) > 1 else s_str\n",
    "\n",
    "tier1a.index = tier1a.index.map(replace_last_underscore_with_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-3vbvPgvbgsi"
   },
   "source": [
    "## **Unweighthed Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3088,
     "status": "ok",
     "timestamp": 1765224659183,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "85hUqwdJFZgT",
    "outputId": "290f2b21-b664-4cdf-a18a-713fe9da0e84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TIER 1 MODEL: AMX\n",
      "==================================================\n",
      "Data prepared for AMX. Total samples: 1089\n",
      "Resistance counts (R=1, S/I=0): AMX\n",
      "1.0    659\n",
      "0.0    430\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.97      0.88        86\n",
      "         1.0       0.97      0.85      0.91       132\n",
      "\n",
      "    accuracy                           0.89       218\n",
      "   macro avg       0.89      0.91      0.89       218\n",
      "weighted avg       0.91      0.89      0.90       218\n",
      "\n",
      "ROC-AUC: 0.941\n",
      " Model trained. Test AUROC: 0.9414\n",
      "AUPRC: 0.9686\n",
      "            gene  shap_importance\n",
      "58         TEM-4         2.370581\n",
      "327     blaTEM-1         0.345772\n",
      "39         OXA-1         0.278450\n",
      "134         sul1         0.267117\n",
      "311        blaEC         0.225393\n",
      "44          PmrE         0.193800\n",
      "36           Mrx         0.151461\n",
      "204  blaTEM-1B_1         0.141080\n",
      "288  aph(3'')-Ib         0.132515\n",
      "16      CTX-M-15         0.123643\n",
      "402       sul2.1         0.123463\n",
      "343      catB3.1         0.102834\n",
      "55       SHV-102         0.100085\n",
      "120         mdtM         0.093286\n",
      "10     APH(6)-Id         0.066095\n",
      "363       emrD.1         0.058205\n",
      "135         sul2         0.055312\n",
      "253       sul2_2         0.047852\n",
      "341        catA1         0.046110\n",
      "258     tet(A)_4         0.045177\n",
      "==================================================\n",
      "TIER 1 MODEL: AMC\n",
      "==================================================\n",
      "Data prepared for AMC. Total samples: 1650\n",
      "Resistance counts (R=1, S/I=0): AMC\n",
      "0.0    1149\n",
      "1.0     501\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.89      0.85       230\n",
      "         1.0       0.67      0.53      0.59       100\n",
      "\n",
      "    accuracy                           0.78       330\n",
      "   macro avg       0.74      0.71      0.72       330\n",
      "weighted avg       0.77      0.78      0.77       330\n",
      "\n",
      "ROC-AUC: 0.820\n",
      " Model trained. Test AUROC: 0.8198\n",
      "AUPRC: 0.7167\n",
      "             gene  shap_importance\n",
      "58          TEM-4         1.448354\n",
      "318      blaOXA-1         0.539091\n",
      "327      blaTEM-1         0.183769\n",
      "258      tet(A)_4         0.124855\n",
      "311         blaEC         0.117043\n",
      "382        mdtM.1         0.095721\n",
      "36            Mrx         0.094146\n",
      "348         dfrA1         0.075047\n",
      "39          OXA-1         0.071891\n",
      "55        SHV-102         0.071038\n",
      "44           PmrE         0.063784\n",
      "134          sul1         0.059041\n",
      "15       CTX-M-14         0.057412\n",
      "352      dfrA17.1         0.050215\n",
      "326        blaTEM         0.048753\n",
      "136          sul3         0.046742\n",
      "102          evgS         0.045542\n",
      "91          dfrA5         0.044733\n",
      "126          mphA         0.041870\n",
      "151  aac(3)-IIa_1         0.035502\n",
      "==================================================\n",
      "TIER 1 MODEL: CIP\n",
      "==================================================\n",
      "Data prepared for CIP. Total samples: 1650\n",
      "Resistance counts (R=1, S/I=0): CIP\n",
      "0.0    1292\n",
      "1.0     358\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.97      0.94       258\n",
      "         1.0       0.88      0.68      0.77        72\n",
      "\n",
      "    accuracy                           0.91       330\n",
      "   macro avg       0.90      0.83      0.85       330\n",
      "weighted avg       0.91      0.91      0.90       330\n",
      "\n",
      "ROC-AUC: 0.935\n",
      " Model trained. Test AUROC: 0.9352\n",
      "AUPRC: 0.8681\n",
      "               gene  shap_importance\n",
      "120            mdtM         0.823300\n",
      "126            mphA         0.571780\n",
      "16         CTX-M-15         0.269340\n",
      "205     blaTEM-1C_5         0.215158\n",
      "343         catB3.1         0.192892\n",
      "0        AAC(3)-IIa         0.183376\n",
      "311           blaEC         0.182961\n",
      "258        tet(A)_4         0.169525\n",
      "204     blaTEM-1B_1         0.158571\n",
      "36              Mrx         0.133613\n",
      "88           dfrA17         0.132066\n",
      "18         CTX-M-55         0.109433\n",
      "68            aadA5         0.108635\n",
      "401          sul1.1         0.103685\n",
      "363          emrD.1         0.099332\n",
      "404        tet(A).1         0.099119\n",
      "138          tet(D)         0.097410\n",
      "44             PmrE         0.093334\n",
      "134            sul1         0.092455\n",
      "159  aac(6')Ib-cr_1         0.089716\n"
     ]
    }
   ],
   "source": [
    "#train Tier 1 models for each drug\n",
    "for drug in ['AMX', 'AMC', 'CIP']:\n",
    "    print(\"=\"*50)\n",
    "    print(f\"TIER 1 MODEL: {drug}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    #find common samples\n",
    "    common_samples = tier1a.index.intersection(phenotypes.index)\n",
    "\n",
    "    X = tier1a.loc[common_samples]\n",
    "\n",
    "    #map phenotypic data to binary (1=Resistant, 0=Susceptible/Intermediate)\n",
    "    y = phenotypes.loc[common_samples, drug].map({'R': 1, 'S': 0, 'I': 0}).dropna()\n",
    "\n",
    "    X = X.loc[y.index]\n",
    "\n",
    "    print(f\"Data prepared for {drug}. Total samples: {len(X)}\")\n",
    "    print(f\"Resistance counts (R=1, S/I=0): {y.value_counts()}\")\n",
    "\n",
    "    ##split Data into Train and Test Sets, We use stratified split to ensure the ratio of Resistant (1) to Susceptible (0) is the same in both the training and testing sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,    #use 20% of data for testing\n",
    "        random_state=42,  #for reproducibility\n",
    "        stratify=y        #essential for imbalanced data like AMR\n",
    "    )\n",
    "\n",
    "    #train XGBoost\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        random_state=42,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #evaluate\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "    auprc = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"\\nResults:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
    "    print(f\" Model trained. Test AUROC: {auroc:.4f}\")\n",
    "    print(f\"AUPRC: {auprc:.4f}\")\n",
    "\n",
    "    # SHAP feature importance\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Get top 20 novel genes\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'gene': X_train.columns,\n",
    "        'shap_importance': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values('shap_importance', ascending=False)\n",
    "\n",
    "    top_20_novel = feature_importance.head(20)\n",
    "    print(top_20_novel)\n",
    "\n",
    "    #save model\n",
    "    model.save_model(f'/content/drive/MyDrive/models/tier1_model_{drug}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKrxnFxucHch"
   },
   "source": [
    "## **Weighted Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3747,
     "status": "ok",
     "timestamp": 1765224637423,
     "user": {
      "displayName": "Colab Projects",
      "userId": "11193673877038850080"
     },
     "user_tz": -300
    },
    "id": "9eOOmRuQTJ3d",
    "outputId": "b8bd03d5-5a66-47e1-c103-07d15dd1041d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TIER 1 MODEL: AMX\n",
      "==================================================\n",
      "Data prepared for AMX. Total samples: 1089\n",
      "Resistance counts (R=1, S/I=0): AMX\n",
      "1.0    659\n",
      "0.0    430\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AMX: Training XGBoost model...\n",
      " - Train Samples: 871 (R=527, S=344)\n",
      " - Test Samples: 218\n",
      " - scale_pos_weight: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [20:10:34] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained. Test AUROC: 0.9350\n",
      "ROC-AUC: 0.935\n",
      "AUPRC: 0.9660\n",
      "Precision: 0.9825\n",
      "Recall: 0.8485\n",
      "F1 Score: 0.9106\n",
      "\n",
      "Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.98      0.88        86\n",
      "         1.0       0.98      0.85      0.91       132\n",
      "\n",
      "    accuracy                           0.90       218\n",
      "   macro avg       0.90      0.91      0.90       218\n",
      "weighted avg       0.91      0.90      0.90       218\n",
      "\n",
      "            gene  shap_importance\n",
      "58         TEM-4         1.745257\n",
      "327     blaTEM-1         0.642719\n",
      "204  blaTEM-1B_1         0.267102\n",
      "39         OXA-1         0.214595\n",
      "311        blaEC         0.206418\n",
      "134         sul1         0.205218\n",
      "44          PmrE         0.201813\n",
      "402       sul2.1         0.155927\n",
      "288  aph(3'')-Ib         0.137484\n",
      "36           Mrx         0.117108\n",
      "120         mdtM         0.104284\n",
      "363       emrD.1         0.083918\n",
      "189   blaOXA-1_1         0.069570\n",
      "55       SHV-102         0.061054\n",
      "135         sul2         0.058966\n",
      "343      catB3.1         0.057970\n",
      "161      aadA1_1         0.054873\n",
      "341        catA1         0.054532\n",
      "138       tet(D)         0.050657\n",
      "251       sul1_2         0.044398\n",
      "\n",
      "--- Training complete for AMX ---\n",
      "==================================================\n",
      "TIER 1 MODEL: AMC\n",
      "==================================================\n",
      "Data prepared for AMC. Total samples: 1650\n",
      "Resistance counts (R=1, S/I=0): AMC\n",
      "0.0    1149\n",
      "1.0     501\n",
      "Name: count, dtype: int64\n",
      "\n",
      "AMC: Training XGBoost model...\n",
      " - Train Samples: 1320 (R=401, S=919)\n",
      " - Test Samples: 330\n",
      " - scale_pos_weight: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [20:10:35] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained. Test AUROC: 0.8255\n",
      "ROC-AUC: 0.826\n",
      "AUPRC: 0.7148\n",
      "Precision: 0.5882\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.6780\n",
      "\n",
      "Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.76      0.82       230\n",
      "         1.0       0.59      0.80      0.68       100\n",
      "\n",
      "    accuracy                           0.77       330\n",
      "   macro avg       0.74      0.78      0.75       330\n",
      "weighted avg       0.80      0.77      0.78       330\n",
      "\n",
      "            gene  shap_importance\n",
      "58         TEM-4         1.121231\n",
      "318     blaOXA-1         0.389447\n",
      "39         OXA-1         0.207375\n",
      "311        blaEC         0.139966\n",
      "258     tet(A)_4         0.116612\n",
      "327     blaTEM-1         0.114794\n",
      "36           Mrx         0.102914\n",
      "135         sul2         0.083075\n",
      "134         sul1         0.071199\n",
      "401       sul1.1         0.069021\n",
      "204  blaTEM-1B_1         0.067930\n",
      "348        dfrA1         0.066062\n",
      "382       mdtM.1         0.064300\n",
      "126         mphA         0.064259\n",
      "352     dfrA17.1         0.059725\n",
      "363       emrD.1         0.054835\n",
      "55       SHV-102         0.052099\n",
      "44          PmrE         0.051188\n",
      "254       sul2_3         0.050352\n",
      "248       strA_4         0.050093\n",
      "\n",
      "--- Training complete for AMC ---\n",
      "==================================================\n",
      "TIER 1 MODEL: CIP\n",
      "==================================================\n",
      "Data prepared for CIP. Total samples: 1650\n",
      "Resistance counts (R=1, S/I=0): CIP\n",
      "0.0    1292\n",
      "1.0     358\n",
      "Name: count, dtype: int64\n",
      "\n",
      "CIP: Training XGBoost model...\n",
      " - Train Samples: 1320 (R=286, S=1034)\n",
      " - Test Samples: 330\n",
      " - scale_pos_weight: 3.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [20:10:36] WARNING: /workspace/src/learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained. Test AUROC: 0.9272\n",
      "ROC-AUC: 0.927\n",
      "AUPRC: 0.8613\n",
      "Precision: 0.7160\n",
      "Recall: 0.8056\n",
      "F1 Score: 0.7582\n",
      "\n",
      "Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.93       258\n",
      "         1.0       0.72      0.81      0.76        72\n",
      "\n",
      "    accuracy                           0.89       330\n",
      "   macro avg       0.83      0.86      0.84       330\n",
      "weighted avg       0.89      0.89      0.89       330\n",
      "\n",
      "               gene  shap_importance\n",
      "120            mdtM         0.756636\n",
      "126            mphA         0.559397\n",
      "205     blaTEM-1C_5         0.230480\n",
      "311           blaEC         0.230048\n",
      "204     blaTEM-1B_1         0.218444\n",
      "258        tet(A)_4         0.208959\n",
      "382          mdtM.1         0.204063\n",
      "16         CTX-M-15         0.194781\n",
      "0        AAC(3)-IIa         0.185926\n",
      "343         catB3.1         0.169481\n",
      "88           dfrA17         0.132326\n",
      "44             PmrE         0.122105\n",
      "159  aac(6')Ib-cr_1         0.114237\n",
      "248          strA_4         0.110890\n",
      "134            sul1         0.107210\n",
      "240        mph(A)_2         0.100478\n",
      "363          emrD.1         0.094051\n",
      "384          mph(A)         0.092521\n",
      "68            aadA5         0.082501\n",
      "18         CTX-M-55         0.080446\n",
      "\n",
      "--- Training complete for CIP ---\n"
     ]
    }
   ],
   "source": [
    "#train Tier 1 models for each drug\n",
    "for drug in ['AMX', 'AMC', 'CIP']:\n",
    "    print(\"=\"*50)\n",
    "    print(f\"TIER 1 MODEL: {drug}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    #find common samples\n",
    "    common_samples = tier1a.index.intersection(phenotypes.index)\n",
    "\n",
    "    X = tier1a.loc[common_samples]\n",
    "\n",
    "    #map phenotypic data to binary (1=Resistant, 0=Susceptible/Intermediate)\n",
    "    y = phenotypes.loc[common_samples, drug].map({'R': 1, 'S': 0, 'I': 0}).dropna()\n",
    "\n",
    "    X = X.loc[y.index]\n",
    "\n",
    "    print(f\"Data prepared for {drug}. Total samples: {len(X)}\")\n",
    "    print(f\"Resistance counts (R=1, S/I=0): {y.value_counts()}\")\n",
    "\n",
    "    ##split Data into Train and Test Sets, We use stratified split to ensure the ratio of Resistant (1) to Susceptible (0) is the same in both the training and testing sets.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,    #use 20% of data for testing\n",
    "        random_state=42,  #for reproducibility\n",
    "        stratify=y        #essential for imbalanced data like AMR\n",
    "    )\n",
    "\n",
    "    data_dict = {}\n",
    "\n",
    "\n",
    "    #calculate Class Weights for Imbalance, Resistance (1) is the positive class.\n",
    "    n_resistant = np.sum(y_train == 1)\n",
    "    n_susceptible = np.sum(y_train == 0)\n",
    "\n",
    "    if n_resistant > 0:\n",
    "        scale_pos_weight = n_susceptible / n_resistant\n",
    "    else:\n",
    "        #fallback if no resistant samples are in the training set (rare but safe)\n",
    "        scale_pos_weight = 1.0\n",
    "\n",
    "    #train XGBoost Model\n",
    "    print(f\"\\n{drug}: Training XGBoost model...\")\n",
    "    print(f\" - Train Samples: {len(X_train)} (R={n_resistant}, S={n_susceptible})\")\n",
    "    print(f\" - Test Samples: {len(X_test)}\")\n",
    "    print(f\" - scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "\n",
    "    #train XGBoost\n",
    "\n",
    "    model = XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    use_label_encoder=False\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    #evaluate Model\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    auroc = roc_auc_score(y_test, y_pred_proba)\n",
    "    auprc = average_precision_score(y_test, y_pred_proba)\n",
    "    precision = precision_score(y_test, y_pred_proba.round())\n",
    "    recall = recall_score(y_test, y_pred_proba.round())\n",
    "    f1 = f1_score(y_test, y_pred_proba.round())\n",
    "\n",
    "\n",
    "    print(f\" Model trained. Test AUROC: {auroc:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_pred_proba):.3f}\")\n",
    "    print(f\"AUPRC: {auprc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    #sore Results\n",
    "    data_dict[drug] = {\n",
    "        'model': model,\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'auroc': auroc\n",
    "    }\n",
    "\n",
    "    print(f\"\\nResults:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # SHAP feature importance\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "    # Get top 20 novel genes\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'gene': X_train.columns,\n",
    "        'shap_importance': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values('shap_importance', ascending=False)\n",
    "\n",
    "    top_20_novel = feature_importance.head(20)\n",
    "    print(top_20_novel)\n",
    "\n",
    "    print(f\"\\n--- Training complete for {drug} ---\")\n",
    "\n",
    "    #save model\n",
    "    model.save_model(f'/content/drive/MyDrive/models/tier1_weighted_model_{drug}.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSb6F7JzWgrN"
   },
   "source": [
    "## **Tier 1 Model Comparison**\n",
    "\n",
    "The **Weighted Models** are superior for **AMC and CIP** because they achieve a better balance between **Precision** and **Recall** for the minority (Resistant) class. The unweighted model performed slightly better on AMX, likely because the imbalance was less severe.\n",
    "\n",
    "| Drug | Model Version | AUROC (Area Under ROC) | AUPRC (Area Under PR Curve) | Precision (R=1) | Recall (R=1) | F1-Score (R=1) | Judgment |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| **AMX** (Balanced, R:S = 1.5:1) | **Unweighted (Default)** | **0.9414** | **0.9686** | 0.97 | 0.85 | 0.91 | **Slightly Better** (Higher Precision/AUROC) |\n",
    "| **AMX** | Weighted (0.65) | 0.9350 | 0.9660 | 0.98 | 0.85 | 0.91 | Very close, similar F1. |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| **AMC** (Imbalanced, R:S = 1:2.3) | Unweighted (Default) | 0.8198 | **0.7167** | **0.67** | 0.53 | 0.59 | **Worse** (Low Recall for Resistance) |\n",
    "| **AMC** | **Weighted (2.29)** | **0.8255** | 0.7148 | 0.59 | **0.80** | **0.68** | **Better** (Higher Recall/F1) |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| **CIP** (Highly Imbalanced, R:S = 1:3.6) | Unweighted (Default) | **0.9352** | **0.8681** | **0.88** | 0.68 | 0.77 | **Worse** (Low Recall for Resistance) |\n",
    "| **CIP** | **Weighted (3.62)** | 0.9272 | 0.8613 | 0.72 | **0.81** | **0.76** | **Better** (Higher Recall/F1) |\n",
    "\n",
    "**`Detailed Analysis by Drug`**\n",
    "\n",
    "**`1. Amoxicillin (AMX) - Relatively Balanced`**\n",
    "* **Best Model:** **Unweighted Model.**\n",
    "* **Reasoning:** Since the class ratio is closer to 1:1, the default XGBoost objective often maximizes overall separation, resulting in a slightly higher **AUROC (0.9414)** and a very high **Precision (0.97)** for the resistant class. The weighted model shows slightly lower AUROC and AUPRC. Both models are excellent.\n",
    "\n",
    "**`2. Amoxicillin/Clavulanate (AMC) - Imbalanced`**\n",
    "* **Best Model:** **Weighted Model ($\\text{scale_pos_weight} = 2.29$).**\n",
    "* **Reasoning:** The unweighted model achieves high precision (0.81) for susceptible (0.0) but only **0.53 Recall** for the resistant (1.0) class. This means it misses almost half of the actual resistant isolates. The weighted model sacrifices a bit of precision (down to **0.59**) to drastically increase **Recall to 0.80**, resulting in a much higher **F1-Score (0.68 vs 0.59)**. This is a vital trade-off in AMR, as **missing resistance (low Recall)** is usually the most dangerous error.\n",
    "\n",
    "**`3. Ciprofloxacin (CIP) - Highly Imbalanced`**\n",
    "* **Best Model:** **Weighted Model ($\\text{scale_pos_weight} = 3.62$).**\n",
    "* **Reasoning:** The imbalance is most severe here. The unweighted model prioritizes accuracy on the large susceptible class, resulting in a very low **Recall of 0.68** for the resistant class. The weighted model successfully redistributes the focus, pushing **Recall up to 0.81**, which is a significant improvement in identifying resistance, and a better **F1-Score (0.76 vs 0.77)** for the resistant class.\n",
    "\n",
    "**`Conclusion`**\n",
    "\n",
    "The **weighted models** provide a better, more robust, and more clinically relevant performance profile for the **imbalanced** drugs (**AMC and CIP**). They successfully use **`scale_pos_weight`** to balance the ability to correctly identify both susceptible and resistant isolates, as shown by the improved Recall and F1-scores for the Resistant (1.0) class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpcrp27oIxmS"
   },
   "source": [
    "# **2. Tier 1B: Stress/Metal Resistance (50 features)**\n",
    "**`File:`** `tier1b_stress_genes.csv`\n",
    "\n",
    "**`Composition:`**\n",
    "- Metal resistance: `arsA`, `merA`, `silB`, `terC`, etc.\n",
    "- Biocide resistance: `qacE`, `emrE`, etc.\n",
    "\n",
    "**`Used for:`**\n",
    "- Flagging co-selection (report genes correlated with these)\n",
    "- Supplementary analysis: \"Genes linked to stress response\"\n",
    "- **`Debatable for Tier 2:`** Could include in multi-tier models if want to capture co-selection dynamics\n",
    "\n",
    "**`Do NOT use for:`**\n",
    "- Strict correlation filtering (we already flagged these separately)\n",
    "\n",
    "**`Examples of Co-Selection Genes:`**\n",
    "\n",
    "- **Arsenic**: `arsA`, `arsD`, `arsR`\n",
    "- **Silver**: `silB`, `silC`, `silE`, `silP`\n",
    "- **Tellurite**: `terB`, `terC`, `terD`, `terE`, `terW`, `terZ`\n",
    "- **Mercury**: `merA`, `merC`, `merD`, `merE`, `merP`, `merR`, `merT`\n",
    "- **Copper**: `pcoC`, `pcoE`\n",
    "\n",
    "| System      | Genes Removed                              | Co-Selection Link                                                                                     | References                                                                                                                                                   |\n",
    "| :---------- | :----------------------------------------- | :---------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| Silver (`sil`) | `silB`, `silC`, `silE`, `silP`             | Often on plasmids with β-lactamases                                                                   | Gupta et al. (1999) demonstrated that silver resistance genes on plasmids are frequently co-located with antibiotic resistance determinants                 |\n",
    "| Mercury (`mer`) | `merA`, `merC`, `merD`, `merE`, `merP`, `merR`, `merT` | Class 1 integrons with AMR cassettes                                                               | Liebert et al. (1999) found mercury resistance genes on conjugative plasmids carrying multiple antibiotic resistance genes                                   |\n",
    "| Tellurite (`ter`) | `terB`, `terC`, `terD`, `terE`, `terW`, `terZ` | Plasmid-borne with AMR genes                                                                      | Turner et al. (1999) reported tellurite resistance operons on mobile genetic elements associated with antibiotic resistance                                 |\n",
    "\n",
    "**Validated**: These genes create linkage disequilibrium (LD) with true AMR genes due to co-location on plasmids. Their removal prevents spurious associations in ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XYEQ43Q9Kb3K"
   },
   "outputs": [],
   "source": [
    "stress = pd.read_csv(\"./tier1b_stress_genes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISOLATE_ID</th>\n",
       "      <th>ariR</th>\n",
       "      <th>arsA</th>\n",
       "      <th>arsD</th>\n",
       "      <th>arsR</th>\n",
       "      <th>clpK</th>\n",
       "      <th>emrE</th>\n",
       "      <th>hdeD-GI</th>\n",
       "      <th>hsp20</th>\n",
       "      <th>kefB-GI</th>\n",
       "      <th>...</th>\n",
       "      <th>silS</th>\n",
       "      <th>terB</th>\n",
       "      <th>terC</th>\n",
       "      <th>terD</th>\n",
       "      <th>terE</th>\n",
       "      <th>terW</th>\n",
       "      <th>terZ</th>\n",
       "      <th>trxLHR</th>\n",
       "      <th>yfdX1</th>\n",
       "      <th>yfdX2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11657_5_1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11657_5_10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11657_5_11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11657_5_12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11657_5_13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11657_5_14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11657_5_15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11657_5_16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11657_5_17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11657_5_18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11657_5_19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11657_5_2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11657_5_20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11657_5_21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11657_5_22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11657_5_23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11657_5_24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11657_5_25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11657_5_26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11657_5_27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ISOLATE_ID  ariR  arsA  arsD  arsR  clpK  emrE  hdeD-GI  hsp20  kefB-GI  \\\n",
       "0    11657_5_1     1     0     0     0     0     0        0      0        0   \n",
       "1   11657_5_10     1     0     0     0     0     0        0      0        0   \n",
       "2   11657_5_11     1     0     0     0     0     1        0      0        0   \n",
       "3   11657_5_12     1     0     0     0     0     1        0      0        0   \n",
       "4   11657_5_13     1     0     0     0     0     1        0      0        0   \n",
       "5   11657_5_14     1     0     1     0     0     0        0      0        0   \n",
       "6   11657_5_15     1     0     0     0     0     1        0      0        0   \n",
       "7   11657_5_16     1     0     0     0     0     1        0      0        0   \n",
       "8   11657_5_17     1     0     0     0     0     1        0      0        0   \n",
       "9   11657_5_18     1     0     0     0     0     1        0      0        0   \n",
       "10  11657_5_19     1     0     0     0     0     1        0      0        0   \n",
       "11   11657_5_2     1     0     0     0     0     1        0      0        0   \n",
       "12  11657_5_20     1     0     0     0     0     0        0      0        0   \n",
       "13  11657_5_21     1     0     0     0     0     0        0      0        0   \n",
       "14  11657_5_22     1     0     0     0     0     1        0      0        0   \n",
       "15  11657_5_23     1     0     0     0     0     1        0      0        0   \n",
       "16  11657_5_24     1     0     0     0     0     1        0      0        0   \n",
       "17  11657_5_25     1     0     0     0     0     1        0      0        0   \n",
       "18  11657_5_26     1     0     0     0     0     1        0      0        0   \n",
       "19  11657_5_27     1     0     0     0     0     1        0      0        0   \n",
       "\n",
       "    ...  silS  terB  terC  terD  terE  terW  terZ  trxLHR  yfdX1  yfdX2  \n",
       "0   ...     0     0     0     0     0     0     0       0      0      0  \n",
       "1   ...     0     0     0     0     0     0     0       0      0      0  \n",
       "2   ...     0     0     0     0     0     0     0       0      0      0  \n",
       "3   ...     0     0     0     0     0     0     0       0      0      0  \n",
       "4   ...     0     0     0     0     0     0     0       0      0      0  \n",
       "5   ...     0     0     0     0     0     0     0       0      0      0  \n",
       "6   ...     0     0     0     0     0     0     0       0      0      0  \n",
       "7   ...     1     0     0     0     0     0     0       0      0      0  \n",
       "8   ...     0     0     0     0     0     0     0       0      0      0  \n",
       "9   ...     0     0     0     0     0     0     0       0      0      0  \n",
       "10  ...     0     0     0     0     0     0     0       0      0      0  \n",
       "11  ...     0     0     0     0     0     0     0       0      0      0  \n",
       "12  ...     0     0     0     0     0     0     0       0      0      0  \n",
       "13  ...     0     0     0     0     0     0     0       0      0      0  \n",
       "14  ...     0     0     0     0     0     0     0       0      0      0  \n",
       "15  ...     0     0     0     0     0     0     0       0      0      0  \n",
       "16  ...     0     0     0     0     0     0     0       0      0      0  \n",
       "17  ...     0     0     0     0     0     0     0       0      0      0  \n",
       "18  ...     0     0     0     0     0     0     0       0      0      0  \n",
       "19  ...     0     0     0     0     0     0     0       0      0      0  \n",
       "\n",
       "[20 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stress.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ISOLATE_ID', 'ariR', 'arsA', 'arsD', 'arsR', 'clpK', 'emrE', 'hdeD-GI',\n",
       "       'hsp20', 'kefB-GI', 'merA', 'merB', 'merC', 'merD', 'merE', 'merF',\n",
       "       'merP', 'merR', 'merT', 'ncrA', 'ncrB', 'ncrC', 'pcoA', 'pcoB', 'pcoC',\n",
       "       'pcoD', 'pcoE', 'pcoR', 'pcoS', 'psi-GI', 'qacE', 'qacEdelta1', 'qacL',\n",
       "       'shsP', 'silA', 'silB', 'silC', 'silE', 'silF', 'silP', 'silR', 'silS',\n",
       "       'terB', 'terC', 'terD', 'terE', 'terW', 'terZ', 'trxLHR', 'yfdX1',\n",
       "       'yfdX2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stress.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNSBUM10FHk7MUBfXRCd1+W",
   "mount_file_id": "1obD0bjJMlZoqdmImXSCVl7HMZfS0U6fK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
